{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRMM7am79f2L"
   },
   "source": [
    "#  자연어 처리를 위한 NLTK와 KoNLPy 설치하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7ZTOF0f9rxn"
   },
   "source": [
    "## NLTK와 NLTK Data 설치\n",
    "- 엔엘티케이(NLTK)는 자연어 처리를 위한 파이썬 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm1kjhqY9rV4",
    "outputId": "f5dffae8-092a-43a4-9bad-d9e707e2f08a"
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "s6ZaZ1W29rA-",
    "outputId": "4effcb3f-a63e-4e89-a752-959f93591922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XEBrKXaD95i-"
   },
   "outputs": [],
   "source": [
    "# 해당 코드를 실행 후에 NLTK 실습에 필요한 각종 패키지와 코퍼스를 다운로드할 수 있다\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiB8SaeG-MF2"
   },
   "source": [
    "## KoNLPY 설치\n",
    "- 코엔엘파이(KoNLPy)는 한국어 자연어 처리를 위한 형태소 분석기 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQwCcSZ8-QhY",
    "outputId": "4b056a8f-54b2-41fa-a209-158fea5b6c78"
   },
   "outputs": [],
   "source": [
    "#!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RotHVV0F-T9K",
    "outputId": "a3ab0d41-510d-4aa3-ebc7-d534d3b62830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 문장분류기(KSS : Korean Sentence Splitter) 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTWOh3lPBxHR",
    "outputId": "731763d2-fc32-4c67-dfe4-e771a1f2c9f2"
   },
   "outputs": [],
   "source": [
    "#! pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhtz-CBQ-hYb"
   },
   "source": [
    "# 텍스트 전처리\n",
    "- 토큰화 : 자연어 처리에서 크롤링 등으로 얻어낸 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)하는 일을 하게된다. 이렇듯 주어진 코퍼스에서 토큰이라 불리는 단위로 나눈 작업을 토큰화 작업이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfB7WrvXMigK"
   },
   "source": [
    "# 품사 태깅(POS-tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7bMGht0OEB2"
   },
   "source": [
    "- 위에서 영어 문장에 대해서 토큰화를 수행하고, 이어서 품사 태깅을 수행하였다. Penn Treebank POG Tags에서 PRP는 인칭 대명사, VBP는 동사, RB는 부사, VBG는 현재부사, IN은 전치사, NNP는 고유 명사, NNS는 복수형 명사, CC는 접속사, DT는 관사를 의미한다.\n",
    "\n",
    "- 각각의 명칭에 대한 줄임말은 다음과 같고, 그 외에 참고할 말한 것들은 다음  사이트에서 확인할 수 있다. [참고링크](https://bluebreeze.co.kr/1357)\n",
    "    - PRP : personal pronoun 인칭 대명사(I, you, he, she)\n",
    "    - VBP : verb, non-third person singular present 3인칭이 아닌 현재형 동사\n",
    "    - RB : adverb\t부사\n",
    "    - VBG : verb, gerund or present 동명사 또는 현재분사(~ing)\n",
    "    - IN : perposition, subordinating conjunction 전치사 종속 접속사\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctD-OCIUM2di"
   },
   "source": [
    "## KoNLPY 활용한 한글 토큰화 실습\n",
    "- 한국어 자연어 처리를 위해서 KoNLPy를 주로 쓴다. KoNLPy를 통해 사용할 수 있는 형태소 분석기로 Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma)가 있다.\n",
    "- 한국어 NLP에서 형태소 분석기를 사용한다는 것은 단어 토큰화가 아니라 정확히는 형태소(morpheme) 단위로 형태소 토큰화(morpheme tokenization)를 수행하게 됨을 뜻한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB_Hk9b2_ZH1"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa7uhkEGAA9a"
   },
   "source": [
    "**Word2Vec의 하이퍼파라미터 값**\n",
    "\n",
    "- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.  \n",
    "- window = 컨텍스트 윈도우 크기  \n",
    "- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)  \n",
    "- workers = 학습을 위한 프로세스 수  \n",
    "- sg = 0은 CBOW, 1은 Skip-gram.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srvblMW4AOcd"
   },
   "source": [
    "## 한국어 데이터 다운로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "QVTI-34CATWb"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/repo/course/sem21_01/youtube_summarizer/jupyter'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "FIdK1h5Gpb4C",
    "outputId": "9b5a7a44-de45-45db-a267-32ed4db70228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (260697, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media</th>\n",
       "      <th>id</th>\n",
       "      <th>article_original</th>\n",
       "      <th>abstractive</th>\n",
       "      <th>extractive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>부산일보</td>\n",
       "      <td>360972161</td>\n",
       "      <td>[지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...</td>\n",
       "      <td>통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...</td>\n",
       "      <td>[4, 11, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중도일보</td>\n",
       "      <td>356659913</td>\n",
       "      <td>[서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...</td>\n",
       "      <td>서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...</td>\n",
       "      <td>[1, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>무등일보</td>\n",
       "      <td>351718460</td>\n",
       "      <td>[지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...</td>\n",
       "      <td>‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...</td>\n",
       "      <td>[0, 2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이데일리</td>\n",
       "      <td>335868123</td>\n",
       "      <td>[서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...</td>\n",
       "      <td>서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울신문</td>\n",
       "      <td>351443347</td>\n",
       "      <td>[미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...</td>\n",
       "      <td>미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  부산일보  360972161  [지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...   \n",
       "1  중도일보  356659913  [서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...   \n",
       "2  무등일보  351718460  [지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...   \n",
       "3  이데일리  335868123  [서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...   \n",
       "4  서울신문  351443347  [미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...   \n",
       "\n",
       "                                         abstractive   extractive  \n",
       "0  통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...  [4, 11, 18]  \n",
       "1  서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...    [1, 3, 4]  \n",
       "2   ‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...    [0, 2, 4]  \n",
       "3  서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...    [0, 1, 2]  \n",
       "4  미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...    [0, 1, 2]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = '/repo/course/sem21_01/youtube_summarizer/dataset/article_dataset/train.jsonl'\n",
    "\n",
    "### bfly train\n",
    "sent_df = pd.read_json(path, lines=True, encoding=\"utf-8\")\n",
    "print('shape : {}'.format(sent_df.shape))\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ' '.join([article[0] for article in sent_df['article_original'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109150"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# 영어 단어가 생각보다 많네?\n",
    "eng = re.findall('([a-zA-Z]{1,})', texts)\n",
    "len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "735k2D9_u4tH",
    "outputId": "17dc6702-4366-4f46-e7a6-34298b3379d7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'bash\\ncd /tmp\\ngit clone https://bitbucket.org/eunjeon/mecab-python-0.996.git\\ncd mecab-python-0.996\\npython3 setup.py build\\npython3 setup.py install\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mecab - 방법1\n",
    "# https://sosomemo.tistory.com/30\n",
    "# Mecab설치\n",
    "'''bash\n",
    "cd /tmp\n",
    "sudo wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
    "sudo tar xvf mecab-0.996-ko-0.9.2.tar.gz\n",
    "\n",
    "cd /tmp/mecab-0.996-ko-0.9.2\n",
    "sudo ./configure\n",
    "sudo make check\n",
    "sudo make install\n",
    "'''\n",
    "\n",
    "'''bash\n",
    "cd /tmp\n",
    "wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "tar zxvf mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "\n",
    "cd /tmp/mecab-ko-dic-2.1.1-20180720\n",
    "sudo ./autogen.sh\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\n",
    "'''\n",
    "\n",
    "'''bash\n",
    "cd /tmp\n",
    "git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git\n",
    "cd mecab-python-0.996\n",
    "python3 setup.py build\n",
    "python3 setup.py install\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnsWHJSgCTV_",
    "outputId": "7b35e545-df50-4ab4-aba6-e24588339b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "curl is already the newest version (7.58.0-2ubuntu3.13).\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.8).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 55 not upgraded.\n",
      "mecab-ko is already installed\n",
      "mecab-ko-dic is already installed\n",
      "mecab-python is already installed\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# mecab 설치 - 방법1\n",
    "# ! pip install konlpy\n",
    "# ! sudo apt-get install curl git\n",
    "# ! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "mULhS6PUrPGY"
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt  \n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "#okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "nToHnaxIGU29"
   },
   "outputs": [],
   "source": [
    "#stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','을','를','으로','자','에','와','한','하다', '합니다', '입니다']\n",
    "stopwords = ['을', '를', '이', '가', '은', '는', '의', '에', '와', '으로', '합니다', '입니다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SWfeawS4NsqC"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjsut73Q8szP"
   },
   "outputs": [],
   "source": [
    "tokenized_news_data = []\n",
    "for news in sent_df['article_original']:\n",
    "    for sentence in news:\n",
    "        #print(f'previous : {sentence}')\n",
    "        tmp_sen = re.sub('[^가-힣a-z]', ' ', sentence) # 영어 소문자와 한글을 제외한 모든 문자를 제거\n",
    "        temp_X = mecab.morphs(tmp_sen) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        #print(f'after : {temp_X}')\n",
    "        tokenized_news_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63Y7RVuEr0kN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/article_tokenized/tokenized_news_data.pkl'\n",
    "\n",
    "# save pickle file\n",
    "with open(pk_path, 'wb') as f:\n",
    "    pickle.dump(tokenized_news_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/article_tokenized/tokenized_news_data.pkl'\n",
    "\n",
    "# load pickle file\n",
    "with open(pk_path, 'rb') as f:\n",
    "     tokenized_news_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_news_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GB1qowgS0iF",
    "outputId": "0a121ff9-9b47-466b-e7fe-989512343c9a"
   },
   "outputs": [],
   "source": [
    "sent_df['article_original'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_news_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df['article_original'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh41lNSUI64T"
   },
   "source": [
    "### import pretrained model\n",
    "**Pretraining 환경**\n",
    "~~~\n",
    "def train_word2vec(corpus_fname, model_fname):\n",
    "    make_save_path(model_fname)\n",
    "    corpus = Word2VecCorpus(corpus_fname)\n",
    "    model = Word2Vec(corpus, size=100, workers=4, sg=1)\n",
    "    model.save(model_fname)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZgwVWwE1iW3"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_path = '/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/word2vec'\n",
    "\n",
    "model = Word2Vec.load(w2v_path)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/word2vec.bin.gz\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh8RGVZBI-ZX"
   },
   "source": [
    "### finetune pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new model\n",
    "model_2 = Word2Vec(size=100, workers=4, sg=1)\n",
    "\n",
    "# make voacb\n",
    "model_2.build_vocab(tokenized_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_examples = model_2.corpus_count\n",
    "print(total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build_vocab([list(model.wv.vocab.keys())], update=True)\n",
    "model_2.intersect_word2vec_format(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/word2vec.bin.gz\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.train(tokenized_news_data, total_examples=total_examples, epochs=model_2.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 단어들이 늘어났는가 확인\n",
    "\n",
    "for k in model_2.wv.vocab:\n",
    "    result = model.wv.vocab.get(k, \"0\")\n",
    "    if result==\"0\":\n",
    "        print(k, end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/word2vec_finetuned.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-30U2RxZI-D2"
   },
   "outputs": [],
   "source": [
    "# https://www.infoking.site/16\n",
    "# https://jjdeeplearning.tistory.com/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fine-tuned Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "model_prac = Word2Vec.load(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/word2vec_finetuned.bin\")\n",
    "\n",
    "model_prac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fd928c210502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_prac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"안녕\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "model_prac.wv.vectors(\"안녕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "O4QYT3BVK64Z",
    "c8R2EM1wHtLm"
   ],
   "machine_shape": "hm",
   "name": "자연어 전처리_실험.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
