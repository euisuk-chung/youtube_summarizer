{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가/수정 사항\n",
    "1. 0:ws 로 기사의 앞부분만 뽑아내고 있는데, 좀더 유튜브 스크립트처럼 하려면 여러 위치에서 뽑아야 할 듯\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/repo/course/sem21_01/youtube_summarizer/jupyter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 260697 records from ../dataset/article_dataset/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "data_path = '../dataset/article_dataset/'\n",
    "news_df = load_jsonl(data_path+'train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# (1) 글자 개수가 너무 작은 경우 없애기 (30글자 이상)\n",
    "# (2) 문장이 적은 경우 해당 기사 없애기 (10문장 이상)\n",
    "news_clean = []\n",
    "for news in news_df:\n",
    "    news_article = news['article_original']\n",
    "    if len(news_article) >= 10:\n",
    "        article_clean = [sent for sent in news_article]\n",
    "        news_clean.append(article_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/repo/course/sem21_01/youtube_summarizer/jupyter'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 추가\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/bertsum')\n",
    "sys.path.append('/repo/course/sem21_01/youtube_summarizer/src/bertsum')\n",
    "sys.path.append('/repo/course/sem21_01/youtube_summarizer/src/subtext/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.data_loader import TextLoader, load_dataset\n",
    "from backbone import args, ExtTransformerEncoder, ExtSummarizer, WindowEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/checkpoint/model_step_24000.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ecbb0f405d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model setting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/checkpoint/model_step_24000.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtSummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/checkpoint/model_step_24000.pt'"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "device = \"cpu\" if args.visible_gpus == -1 else \"cuda\"\n",
    "loader = TextLoader(args, device)\n",
    "\n",
    "# model setting\n",
    "# ckpt_path = '/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/checkpoint/model_step_24000.pt'\n",
    "\n",
    "checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model = ExtSummarizer(args, device, checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Trainingset (dev/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dt = 50000\n",
    "df_base = news_clean[:max_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셔플링\n",
    "random.seed(1234)\n",
    "random.shuffle(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "window_size = 3\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_raio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_base: 35000, Val_base: 7500, Test_base: 7500\n"
     ]
    }
   ],
   "source": [
    "train_len, val_len = int(len(df_base)*train_ratio), int(len(df_base)*val_ratio)\n",
    "test_len = len(df_base) - (train_len + val_len)\n",
    "print(f\"Train_base: {train_len}, Val_base: {val_len}, Test_base: {test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = df_base[:train_len]\n",
    "val_base = df_base[train_len:train_len+val_len]\n",
    "test_base = df_base[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(base_dataset=None, y_ratio=0.5, window_size=4):\n",
    "    '''\n",
    "    y_data: Mixed article\n",
    "    n_data: Normal article\n",
    "    '''\n",
    "    tot_len = base_dataset.__len__()\n",
    "    y_len = int(tot_len * y_ratio)\n",
    "    \n",
    "    y_cands = base_dataset[:y_len]\n",
    "    n_cands = base_dataset[y_len:]\n",
    "    \n",
    "    y_dataset, n_dataset = [], []\n",
    "    for i in tqdm(range(len(y_cands) - 1), desc='Sampling Y dataset'):\n",
    "        tmp_article_y = y_cands[i][:window_size] + y_cands[i+1][:window_size]\n",
    "        y_dataset.append(tmp_article_y)\n",
    "        \n",
    "    for j in tqdm(range(len(n_cands)), desc='Sampling N dataset'):\n",
    "        tmp_article_n = n_cands[j][:window_size*2]\n",
    "        n_dataset.append(tmp_article_n)\n",
    "        \n",
    "    return y_dataset, n_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Y dataset: 100%|██████████| 17499/17499 [00:00<00:00, 456222.27it/s]\n",
      "Sampling N dataset: 100%|██████████| 17500/17500 [00:00<00:00, 663373.79it/s]\n",
      "Sampling Y dataset: 100%|██████████| 3749/3749 [00:00<00:00, 773536.29it/s]\n",
      "Sampling N dataset: 100%|██████████| 3750/3750 [00:00<00:00, 964178.26it/s]\n",
      "Sampling Y dataset: 100%|██████████| 3749/3749 [00:00<00:00, 868705.91it/s]\n",
      "Sampling N dataset: 100%|██████████| 3750/3750 [00:00<00:00, 681129.40it/s]\n"
     ]
    }
   ],
   "source": [
    "train_div, train_org = make_dataset(base_dataset=train_base, y_ratio=0.5, window_size=window_size)\n",
    "val_div, val_org = make_dataset(base_dataset=val_base, y_ratio=0.5, window_size=window_size)\n",
    "test_div, test_org = make_dataset(base_dataset=test_base, y_ratio=0.5, window_size=window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = WindowEmbedder(model=model, window_size=window_size, text_loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "working on articles: 100%|██████████| 17499/17499 [52:26<00:00,  5.56it/s] \n",
      "working on articles: 100%|██████████| 17500/17500 [52:46<00:00,  5.53it/s] \n",
      "working on articles: 100%|██████████| 3749/3749 [10:57<00:00,  5.70it/s]\n",
      "working on articles: 100%|██████████| 3750/3750 [11:04<00:00,  5.65it/s]\n",
      "working on articles: 100%|██████████| 3749/3749 [11:32<00:00,  5.42it/s]\n",
      "working on articles: 100%|██████████| 3750/3750 [12:33<00:00,  4.98it/s]\n"
     ]
    }
   ],
   "source": [
    "tot_datasets = [train_div, train_org, val_div, val_org, test_div, test_org]\n",
    "#tot_datasets = [test_org]\n",
    "\n",
    "tot_embs = []\n",
    "for dt in tot_datasets:\n",
    "    tmp_emb = []\n",
    "    for article in tqdm(dt, desc=\"working on articles\"):\n",
    "        embedding = embedder.get_embeddings(article)\n",
    "        if embedding.size()[0] == window_size*2:\n",
    "            tmp_emb.append(embedding.unsqueeze(0))\n",
    "    tmp_dt_emb = torch.cat(tmp_emb, dim=0)\n",
    "    tot_embs.append(tmp_dt_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save_path = f\"/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/subtext/dataset/nn_dataset_w{window_size}.pkl\"\n",
    "\n",
    "with open(data_save_path, 'wb') as ww:\n",
    "    pickle.dump(tot_embs, ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "with open(data_save_path, 'rb') as rr:\n",
    "    tot_embs = pickle.load(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17350, 8, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_embs[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset (window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
