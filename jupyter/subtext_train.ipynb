{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 추가\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_div, train_org<br>\n",
    "val_div, val_org<br>\n",
    "test_div, test_org<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f'/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/subtext/dataset/nn_dataset_w{window_size}.pkl'\n",
    "\n",
    "with open(data_path, 'rb') as rr:\n",
    "    dataset = pickle.load(rr)\n",
    "\n",
    "dataset_fin = [data.permute(0, 2, 1) for data in dataset]\n",
    "\n",
    "train_x = torch.cat((dataset_fin[0], dataset_fin[1]), dim=0).to(device)\n",
    "train_y = torch.cat((torch.ones(len(dataset_fin[0])), torch.zeros(len(dataset_fin[1]))), dim=0).to(device)\n",
    "\n",
    "val_x = torch.cat((dataset_fin[2], dataset_fin[3]), dim=0).to(device)\n",
    "val_y = torch.cat((torch.ones(len(dataset_fin[2])), torch.zeros(len(dataset_fin[3]))), dim=0).to(device)\n",
    "\n",
    "test_x = torch.cat((dataset_fin[4], dataset_fin[5]), dim=0).to(device)\n",
    "test_y = torch.cat((torch.ones(len(dataset_fin[4])), torch.zeros(len(dataset_fin[5]))), dim=0).to(device)\n",
    "\n",
    "# batch iterator\n",
    "batch_size = 256\n",
    "\n",
    "trainset = data_utils.TensorDataset(train_x, train_y)\n",
    "train_loader = data_utils.DataLoader(trainset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "valset = data_utils.TensorDataset(val_x, val_y)\n",
    "val_loader = data_utils.DataLoader(valset, batch_size = len(valset), shuffle = True)\n",
    "\n",
    "testset = data_utils.TensorDataset(test_x, test_y)\n",
    "test_loader = data_utils.DataLoader(testset, batch_size = len(testset), shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_features):\n",
    "        super(ChunkClassifier, self).__init__()\n",
    "        \n",
    "        # block1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=768, out_channels=128, kernel_size=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Linear(128*3, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # forward block 1\n",
    "        out = self.block1(x)\n",
    "        batch_size = out.size()[0]\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.block2(out)\n",
    "        \n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChunkClassifier(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv1d(768, 128, kernel_size=(4,), stride=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_model = ChunkClassifier(x_features = 768)\n",
    "\n",
    "chunk_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.BCEWithLogitsLoss()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(chunk_model.parameters(), lr = learning_rate)\n",
    "\n",
    "decayRate = 0.998\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer = optimizer, gamma = decayRate)\n",
    "\n",
    "num_batches = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done.\n",
      "0.9515, 0.9755\n",
      "\n",
      "Epoch 2 done.\n",
      "0.9798, 0.9804\n",
      "\n",
      "Epoch 3 done.\n",
      "0.9848, 0.9819\n",
      "\n",
      "Epoch 4 done.\n",
      "0.9875, 0.9823\n",
      "\n",
      "Epoch 5 done.\n",
      "0.9905, 0.9815\n",
      "\n",
      "Epoch 6 done.\n",
      "0.9927, 0.9799\n",
      "\n",
      "Epoch 7 done.\n",
      "0.9955, 0.9815\n",
      "\n",
      "Epoch 8 done.\n",
      "0.9943, 0.9827\n",
      "\n",
      "Epoch 9 done.\n",
      "0.9967, 0.9828\n",
      "\n",
      "Epoch 10 done.\n",
      "0.9977, 0.9833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_corrects_sum = 0.0\n",
    "val_corrects_sum = 0.0\n",
    "\n",
    "train_tot_num = train_loader.dataset.__len__()\n",
    "val_tot_num = val_loader.dataset.__len__()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss_sum = 0.0\n",
    "    \n",
    "    for i, train_block in enumerate(train_loader):\n",
    "        \n",
    "        train_X, train_Y = train_block[0], train_block[1]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # loss 계산\n",
    "        train_pred = chunk_model(train_X)\n",
    "        train_loss = crit(train_pred, train_Y)\n",
    "        train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Prediction Accuracy\n",
    "        train_pred_label = (train_pred > 0.0).float()\n",
    "        train_corrects = (train_pred_label == train_Y).sum()\n",
    "        train_corrects_sum += train_corrects.item()\n",
    "        \n",
    "        train_loss_sum += train_loss\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        val_loss_sum = 0.0\n",
    "        for j, val_block in enumerate(val_loader):\n",
    "            val_X, val_Y = val_block[0], val_block[1]\n",
    "\n",
    "            val_pred = chunk_model(val_X)\n",
    "            val_loss = crit(val_pred, val_Y)\n",
    "            val_loss_sum += val_loss\n",
    "\n",
    "            val_pred_label = (val_pred > 0.0).float()\n",
    "            val_corrects = (val_pred_label == val_Y).sum()\n",
    "            val_corrects_sum += val_corrects.item()\n",
    "\n",
    "    train_loss_sum = 0.0\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} done.\")\n",
    "    print(f\"{train_corrects_sum/train_tot_num:.4f}, {val_corrects_sum/val_tot_num:.4f}\\n\")\n",
    "    \n",
    "    train_corrects_sum = 0.0\n",
    "    val_corrects_sum = 0.0\n",
    "    \n",
    "    # learning rate decaying\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "chunk_model.eval()\n",
    "\n",
    "test_tot_num = test_loader.dataset.__len__()\n",
    "for i, test_block in enumerate(test_loader):\n",
    "    test_X, test_Y = test_block[0], test_block[1]\n",
    "\n",
    "    test_pred = chunk_model(test_X)\n",
    "    test_pred_label = (test_pred > 0.0).float()\n",
    "    test_corrects = (test_pred_label == test_Y).sum()\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_corrects.item()/test_tot_num:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at: /home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/subtext/chunk_nn/ckpt/chunk_model_w3_ckpt.pt\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "save_pth = f'/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/subtext/chunk_nn/ckpt/chunk_model_w{window_size}_ckpt.pt'\n",
    "torch.save(chunk_model.state_dict(), save_pth)\n",
    "print(f\"Model Saved at: {save_pth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChunkClassifier(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv1d(768, 128, kernel_size=(4,), stride=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "window_size = 3\n",
    "model_pth = f'/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/subtext/chunk_nn/ckpt/chunk_model_w{window_size}_ckpt.pt'\n",
    "\n",
    "chunk_model.load_state_dict(torch.load(model_pth))\n",
    "chunk_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.data_loader import TextLoader, load_dataset\n",
    "from bertsum import args, ExtTransformerEncoder, ExtSummarizer, WindowEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtSummarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(8004, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ext_layer): ExtTransformerEncoder(\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (transformer_inter): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "device = \"cpu\" if args.visible_gpus == -1 else \"cuda\"\n",
    "loader = TextLoader(args, device)\n",
    "\n",
    "# model setting\n",
    "ckpt_path = '/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/checkpoint/model_step_24000.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model = ExtSummarizer(args, device, checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = WindowEmbedder(model=model, text_loader=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 기사 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 260697 records from /home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/dataset/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/sks/korea_univ/21_1/TA/project/video_summarizer/Youtube-Summarizer/src/bertsum/dataset'\n",
    "news_df = load_jsonl(os.path.join(data_path, 'train.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# (1) 글자 개수가 너무 작은 경우 없애기 (30글자 이상)\n",
    "# (2) 문장이 적은 경우 해당 기사 없애기 (10문장 이상)\n",
    "news_clean = []\n",
    "for news in news_df:\n",
    "    news_article = news['article_original']\n",
    "    if len(news_article) >= 10:\n",
    "        article_clean = [sent for sent in news_article]\n",
    "        news_clean.append(article_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article=\"\"\"\n",
    "무주택자는 우대를 받아 여기에 10%를 더 빌릴 수 있는데 이런 우대를 더 많은 대상에게 확대 적용하겠다는 겁니다.\n",
    "당정은 소득을 따져서 부채 규모를 제한하는 dsr 규제도 완화하는 방안을 앞으로 논의할 계획입니다.\n",
    "국회 정무위 민주당 간사인 김병욱 의원은 1가구 1주택 종합부동산세 적용 기준을 현행 9억 원에서 12억 원으로 상향하는 법안을 발의했습니다.\n",
    "민주당에서는 재보선 패배 이후 부동산 세제를 완화하자는 주장이 개별적인 차원이지만 이어지고 있습니다.\n",
    "국민의 힘은 늦어지는 백신 수급에 문제를 제기하며 다음 달 한미정상회담에서 문재인 대통령이 코로나19 백신을 충분히 확보해야 한다고 지적했습니다.\n",
    "국민의 힘 주호영 당 대표 권한대행은 미국 방문의 가장 중요한 의제는 백신 확보가 돼야 한다면서 좋은 코로나19 백신을 어떻게 많이 확보하느냐에 우리 외교력의 성적표가 달려있다고 강조했습니다.\n",
    "정부가 올해 2분기에 도입하겠다고 밝혔던 모더나 백신은 상반기 확보가 어려울 전망입니다.\n",
    "홍남기 국무총리 대행은 오늘 국회 대정부질문에서 문 대통령이 모두나 최고경영자와 화상통화를 확보했다는 모두나 백신은 어디 있느냐는 국민의 힘 김은혜 의원의 질문에 이같이 답했습니다.\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "test_article = [sent for sent in test_article if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article=\"\"\"\n",
    "무주택자는 우대를 받아 여기에 10%를 더 빌릴 수 있는데 이런 우대를 더 많은 대상에게 확대 적용하겠다는 겁니다.\n",
    "당정은 소득을 따져서 부채 규모를 제한하는 dsr 규제도 완화하는 방안을 앞으로 논의할 계획입니다.\n",
    "국회 정무위 민주당 간사인 김병욱 의원은 1가구 1주택 종합부동산세 적용 기준을 현행 9억 원에서 12억 원으로 상향하는 법안을 발의했습니다.\n",
    "민주당에서는 재보선 패배 이후 부동산 세제를 완화하자는 주장이 개별적인 차원이지만 이어지고 있습니다.\n",
    "신고를 받은 경찰이 도착해 가까스로 상황이 일단락됩니다.\n",
    "피해 직원은 본인을 도둑 취급했다는 것에 분노한 것은 이해할 수 있지만 그렇다고 폭력이 정당화될 수는 없다고 kbs에 말했습니다.\n",
    "명백한 폭행 사건으로 보이지만 처벌이 가능할지는 미지수입니다 우리나라가 가입한 외교관계에 관한 비엔나 협약에 외교관의 가족은 주재국의 형사 재판을 받지 않는다고 규정돼 있어서입니다.\n",
    "우리나라 법정에서 재판을 받으려면 벨기에 정부가 이런 면책 특권을 포기하는 방법밖에 없지만 그럴 가능성은 없어 보입니다.\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "test_article = [sent for sent in test_article if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article=\"\"\"\n",
    "특허받은 콘덴서 자동세척 시스템 건조 때마다 1~3회 자동세척 청소할 필요가 없다는 등의 광고 문구가 등장합니다.\n",
    "하지만 이런 기능에도 불구하고 적잖은 소비자들이 기계 내 먼지 사인과 악취 등을 호소했고 결국 lg전자는 리콜과 무상보증을 결정했습니다.\n",
    "이불 털기나 소량 건조 등 상황에 따라 자동세척 시스템이 작동하지 않는 문제가 있었던 겁니다.\n",
    "공정거래위원회는 이를 토대로 당시 lg전자의 광고가 거짓 과장 광고에 해당한다고 결론냈습니다.\n",
    "광고를 본 소비자들은 자동 세척 시스템만 있으면 언제나 깨끗한 상태의 건조기를 쓸 수 있을 걸로 오인하게 된다는 겁니다.\n",
    "lg전자 측은 깨끗하게와 같은 표현은 실증의 대상이 아니며 자동 세척이 안 되는 건 소량 빨래 같은 예외적인 상황이었다고 주장했지만 받아들여지지 않았습니다.\n",
    "자동세척 시스템의 성능 효과와 관련된 상임으로 실정이 대상이 되고 특히 일 아주 건조 목적의 공익이 증가하는 것 등을 고려하였을 때 소량 건조가 예외적인 상황은 아니라고 판단하였습니다.\n",
    "공정위는 콘덴서 자동세척 기능이 건조기의 핵심 선택 기준 가운데 하나로 광고되는 등 소비자의 선택에 큰 영향을 미쳤다며 lg전자의 시정 공표 명령과 함께 과징금 3억 9천만 원을 부과했습니다.\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "test_article = [sent for sent in test_article if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article=\"\"\"\n",
    "광고를 본 소비자들은 자동 세척 시스템만 있으면 언제나 깨끗한 상태의 건조기를 쓸 수 있을 걸로 오인하게 된다는 겁니다.\n",
    "lg전자 측은 깨끗하게와 같은 표현은 실증의 대상이 아니며 자동 세척이 안 되는 건 소량 빨래 같은 예외적인 상황이었다고 주장했지만 받아들여지지 않았습니다.\n",
    "자동세척 시스템의 성능 효과와 관련된 상임으로 실정이 대상이 되고 특히 일 아주 건조 목적의 공익이 증가하는 것 등을 고려하였을 때 소량 건조가 예외적인 상황은 아니라고 판단하였습니다.\n",
    "공정위는 콘덴서 자동세척 기능이 건조기의 핵심 선택 기준 가운데 하나로 광고되는 등 소비자의 선택에 큰 영향을 미쳤다며 lg전자의 시정 공표 명령과 함께 과징금 3억 9천만 원을 부과했습니다.\n",
    "식용 옥수수 수입 시 적용되는 관세율을 올 12월 31일까지 0%까지 인하하는 내용을 담은 탈당 관세 규정 개정안이 오늘 국무회의를 통과했습니다.\n",
    "이에 따라 연말까지 수입되는 식용 옥수수 총 128만 톤에 대한 관세율이 기존 3%에서 0%로 내려갑니다.\n",
    "이번 조치는 국제 곡물 가격 상승에 선제적으로 대응하는 취지에서 이뤄졌습니다.\n",
    "기획재정부는 식용 옥수수가 전분 전분당으로 가공돼 제과 제빵 제면 등 식품 원료로 사용되기 때문에 이번 조치가 식품 가격 안정에 기여할 것으로 예상된다고 밝혔습니다.\n",
    "\"\"\".split('\\n')\n",
    "\n",
    "test_article = [sent for sent in test_article if sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 유튜브 스크립트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import doc_preprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_script_pth = '/home/sks/korea_univ/21_1/TA/project/video_dataset/youtube-summarization/data/label/KBS뉴스_NSBlDZeLeLw_27m_36s.txt'\n",
    "with open(youtube_script_pth, 'rb') as rr:\n",
    "    youtube_df = json.load(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = youtube_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_fin = doc_preprocess(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_list = [sent for sent in script_fin.split('\\n') if len(sent.strip()) >= 20][:50]\n",
    "#script_list = [sent for sent in script_fin.split('\\n')][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.19it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_model.eval()\n",
    "\n",
    "score_list = []\n",
    "for i, sent in enumerate(tqdm(script_list)):\n",
    "    if i + (ws*2) <= len(script_list):\n",
    "        w_input = script_list[i:i+(ws*2)]\n",
    "        \n",
    "        # embedding\n",
    "        emb = embedder.get_embeddings(w_input).transpose(1, 0).cuda()\n",
    "        score = chunk_model(emb.unsqueeze(0))\n",
    "        score_list.append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['여러분 안녕하십니까 코로나19 통합뉴스룸 5시 뉴스입니다',\n",
       " '정부와 민주당이 부동산 관련 대출 규제 완화를 검토하기 시작했습니다',\n",
       " '주택 실수요자에 한해 대출 우대를 확대하는 방안이 논의되고 있습니다',\n",
       " '한편 국민의 힘은 다음 달 한미 정상회담에서 코로나19 백신을 최대한 확보할 것을 정부에 주문했습니다',\n",
       " '정부와 더불어민주당은 오늘 국회에서 비공개 당정협의를 열고 주택담보인정비율 ltv의 비율을 높여주는 우대 대상을 확대하는 방안을 논의했습니다',\n",
       " '현재 9억 원 이하 주택은 서울 같은 투기지역 등 규제 지역에선 집값의 40%만 조정대상지역은 50%를 대출받을 수 있습니다',\n",
       " '무주택자는 우대를 받아 여기에 10%를 더 빌릴 수 있는데 이런 우대를 더 많은 대상에게 확대 적용하겠다는 겁니다',\n",
       " '당정은 소득을 따져서 부채 규모를 제한하는 dsr 규제도 완화하는 방안을 앞으로 논의할 계획입니다',\n",
       " '국회 정무위 민주당 간사인 김병욱 의원은 1가구 1주택 종합부동산세 적용 기준을 현행 9억 원에서 12억 원으로 상향하는 법안을 발의했습니다',\n",
       " '민주당에서는 재보선 패배 이후 부동산 세제를 완화하자는 주장이 개별적인 차원이지만 이어지고 있습니다',\n",
       " '국민의 힘은 늦어지는 백신 수급에 문제를 제기하며 다음 달 한미정상회담에서 문재인 대통령이 코로나19 백신을 충분히 확보해야 한다고 지적했습니다',\n",
       " '국민의 힘 주호영 당 대표 권한대행은 미국 방문의 가장 중요한 의제는 백신 확보가 돼야 한다면서 좋은 코로나19 백신을 어떻게 많이 확보하느냐에 우리 외교력의 성적표가 달려있다고 강조했습니다',\n",
       " '정부가 올해 2분기에 도입하겠다고 밝혔던 모더나 백신은 상반기 확보가 어려울 전망입니다',\n",
       " '홍남기 국무총리 대행은 오늘 국회 대정부질문에서 문 대통령이 모두나 최고경영자와 화상통화를 확보했다는 모두나 백신은 어디 있느냐는 국민의 힘 김은혜 의원의 질문에 이같이 답했습니다',\n",
       " '홍 총리 대행은 모두 나눈 4천만 도스 2천만 명 분을 계약했다며 상당 부분이 상반기에는 물량이 많이 들어올 수가 없는 상황이고 하반기에는 들어오게 돼 있다고 설명했습니다',\n",
       " '노형욱 국토교통부 장관 후보자가 세종시 소재 아파트를 특별공급으로 분양받은 뒤 입주를 하지 않은 채 4년 만에 2억 원의 차익을 남겼다는 주장이 제기됐습니다',\n",
       " '주호영 국민의 힘 대표 권한대행은 국회에서 열린 원내대책회의에서 이같이 주장하고 부동산 가격 상승과 투기를 잡기 위해 임명된 자리에 가는 게 문제가 없는지 따져주기 바란다고 말했습니다',\n",
       " '이에 대해 국토부는 2011년 특별공급 당시에는 실거주하려는 의향이 있었지만 2013년 입주 시점에 가족들이 학업과 직장 문제로 서울에 남겠다는 뜻을 밝혔고 당시 노 후보자가 서울 왕래가 잦은 기획재정부 예산실 담당 국장이어서 세종에 살기 힘든 상황이었다고 설명했습니다',\n",
       " '국토부는 또 노 후보자가 2013년부터 4년간 전세를 주다가 2017년 문재인 정부 출범 이후 고위 공직자의 다주택 처분 권고에 따라 세종 아파트를 팔았다면서 시세 차익을 노린 투기는 아니었다고 해명했습니다',\n",
       " '또 향후 후보자는 현재 서울 서초구 반포동 아파트 한 채를 보유하고 있습니다',\n",
       " '공정거래위원회가 확률형 아이템의 확률을 공개하지 않거나 속였다는 의혹을 받고 있는 넥슨코리아에 대한 현장조사에 착수했습니다',\n",
       " '공정위는 오늘 경기도 성남에 있는 넥슨코리아 본사에 조사관 10여 명을 보내 조사를 벌이고 있습니다',\n",
       " '앞서 하태경 의원은 넥슨의 메이플스토리와 던져낸 파이터 마비노기 등이 전자상거래법을 위반했다며 조사를 의뢰한 바 있습니다',\n",
       " '미 항공우주국 나사의 우주헬기가 화성의 하늘을 비행하는 데 성공했습니다',\n",
       " '지구 밖 행성에서 제어가 되는 동력체의 첫 비행이 성공하면서 우주 개척사의 새 장을 열었다는 평가입니다',\n",
       " '화성 표면에서 불과 3m 상공 단 30여 초간의 짧은 비행이었지만 지구가 아닌 행성에서 제어가 되는 동력체로서는 첫 비행이 성공하는 순간입니다',\n",
       " '미국 항공우주국 나사의 화성 탐사 우주헬기 인제니어티가 현지시간으로 19일 화성 하늘을 비행하는 데 성공했습니다',\n",
       " '지구에서 이 과정을 초조하게 지켜본 미국 항공우주국 나사 관계자들은 흥분을 감추지 못했습니다',\n",
       " '인제니어티는 지구에 비해 100분의 1에 불과한 화성의 대기 밀도는 물론 지구의 3분의 1인 중력 등을 고려해 제작됐습니다',\n",
       " '탄소섬유 재질의 날개로 일반 헬기보다 5배가량 빠르게 회전시켰습니다',\n",
       " '제작비용은 8500만 달러 약 950억 원가량이 투입됐는데 인제 뉴티는 앞으로 4차례 더 화성 상공을 시험 비행할 예정입니다',\n",
       " '지구 이외의 행성에서 제어가 되는 동력체의 비행이 성공함으로써 우주탐사는 새로운 장을 열게 됐습니다',\n",
       " '나사 관계자들은 화성 상공에서의 첫 동력 비행이 지난 1903년 라이트 형제의 동력 비행이 항공사의 새장을 연 것처럼 우주 개척의 새로운 이정표가 될 것으로 기대하고 있습니다',\n",
       " '오세훈 서울시장은 오늘 서울시청에서 긴급 브리핑을 열고 전임 박원순 시장 시절 있었던 성희롱 성폭력 사건에 대해 사과했습니다',\n",
       " '오 시장은 또 피해자로부터 재조사 요청을 받은 사실을 공개하며 사건 재조사 방침도 밝혔습니다',\n",
       " '오 시장은 특히 서울시가 박 전 시장의 장례식을 서울시 기관장으로 치르면서 피해자는 절망할 수밖에 없었을 것이라며 당시 관련 책임자를 인사 조치했다고 말했습니다',\n",
       " '오 시장은 성폭력 사건에 대해 원스트라이크 아웃제를 즉시 도입하고 2차 피해에 대해서는 한 치의 관용조차 없을 것이라고 말했습니다',\n",
       " '아무것도 아니야 최근 주한 벨기에 대사 부인이 옷가게 점원의 뺨을 때려 논란이 됐는데요',\n",
       " '당시 폭행 장면이 담긴 cctv 영상을 확보했습니다',\n",
       " '면책 특권 때문에 처벌할 수 있을지 불투명한데 당사자는 경찰의 출석 요구에도 응하지 않고 있습니다',\n",
       " '지난 9일 서울 용산구의 한 옷가게 한 여성이 들어와 옷을 입어봅니다',\n",
       " '피터 레스쿠이의 주한 벨기에 대사해 보인 A 씨입니다',\n",
       " 'A 씨가 옷가게를 둘러본 뒤 매장을 나서자 한 점원이 그 뒤를 쫓아갑니다',\n",
       " 'A 씨는 우연히 이 옷가게에서 판 옷과 똑같은 옷을 입고 있었는데 점원은 A씨가 옷을 입어본 뒤 돈을 안 내고 그냥 나간 걸로 오해한 겁니다',\n",
       " '점원이 옷가게로 돌아온 뒤 A씨도 매장으로 뒤따라와 해당 직원을 끌어내려 합니다',\n",
       " '말리던 다른 직원을 밀치고 뺨을 때리기도 했습니다',\n",
       " '신고를 받은 경찰이 도착해 가까스로 상황이 일단락됩니다',\n",
       " '피해 직원은 본인을 도둑 취급했다는 것에 분노한 것은 이해할 수 있지만 그렇다고 폭력이 정당화될 수는 없다고 kbs에 말했습니다',\n",
       " '명백한 폭행 사건으로 보이지만 처벌이 가능할지는 미지수입니다',\n",
       " '우리나라가 가입한 외교관계에 관한 비엔나 협약에 외교관의 가족은 주재국의 형사 재판을 받지 않는다고 규정돼 있어서입니다']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여러분 안녕하십니까 코로나19 통합뉴스룸 5시 뉴스입니다\n",
      "정부와 민주당이 부동산 관련 대출 규제 완화를 검토하기 시작했습니다\n",
      "주택 실수요자에 한해 대출 우대를 확대하는 방안이 논의되고 있습니다\n",
      "-6.11 \n",
      " 한편 국민의 힘은 다음 달 한미 정상회담에서 코로나19 백신을 최대한 확보할 것을 정부에 주문했습니다\n",
      "-2.87 \n",
      " 정부와 더불어민주당은 오늘 국회에서 비공개 당정협의를 열고 주택담보인정비율 ltv의 비율을 높여주는 우대 대상을 확대하는 방안을 논의했습니다\n",
      "-5.43 \n",
      " 현재 9억 원 이하 주택은 서울 같은 투기지역 등 규제 지역에선 집값의 40%만 조정대상지역은 50%를 대출받을 수 있습니다\n",
      "-5.39 \n",
      " 무주택자는 우대를 받아 여기에 10%를 더 빌릴 수 있는데 이런 우대를 더 많은 대상에게 확대 적용하겠다는 겁니다\n",
      "-4.99 \n",
      " 당정은 소득을 따져서 부채 규모를 제한하는 dsr 규제도 완화하는 방안을 앞으로 논의할 계획입니다\n",
      "2.74 \n",
      " 국회 정무위 민주당 간사인 김병욱 의원은 1가구 1주택 종합부동산세 적용 기준을 현행 9억 원에서 12억 원으로 상향하는 법안을 발의했습니다\n",
      "-2.51 \n",
      " 민주당에서는 재보선 패배 이후 부동산 세제를 완화하자는 주장이 개별적인 차원이지만 이어지고 있습니다\n",
      "6.86 \n",
      " 국민의 힘은 늦어지는 백신 수급에 문제를 제기하며 다음 달 한미정상회담에서 문재인 대통령이 코로나19 백신을 충분히 확보해야 한다고 지적했습니다\n",
      "-4.63 \n",
      " 국민의 힘 주호영 당 대표 권한대행은 미국 방문의 가장 중요한 의제는 백신 확보가 돼야 한다면서 좋은 코로나19 백신을 어떻게 많이 확보하느냐에 우리 외교력의 성적표가 달려있다고 강조했습니다\n",
      "-5.13 \n",
      " 정부가 올해 2분기에 도입하겠다고 밝혔던 모더나 백신은 상반기 확보가 어려울 전망입니다\n",
      "-2.35 \n",
      " 홍남기 국무총리 대행은 오늘 국회 대정부질문에서 문 대통령이 모두나 최고경영자와 화상통화를 확보했다는 모두나 백신은 어디 있느냐는 국민의 힘 김은혜 의원의 질문에 이같이 답했습니다\n",
      "-2.61 \n",
      " 홍 총리 대행은 모두 나눈 4천만 도스 2천만 명 분을 계약했다며 상당 부분이 상반기에는 물량이 많이 들어올 수가 없는 상황이고 하반기에는 들어오게 돼 있다고 설명했습니다\n",
      "5.94 \n",
      " 노형욱 국토교통부 장관 후보자가 세종시 소재 아파트를 특별공급으로 분양받은 뒤 입주를 하지 않은 채 4년 만에 2억 원의 차익을 남겼다는 주장이 제기됐습니다\n",
      "-4.72 \n",
      " 주호영 국민의 힘 대표 권한대행은 국회에서 열린 원내대책회의에서 이같이 주장하고 부동산 가격 상승과 투기를 잡기 위해 임명된 자리에 가는 게 문제가 없는지 따져주기 바란다고 말했습니다\n",
      "-5.54 \n",
      " 이에 대해 국토부는 2011년 특별공급 당시에는 실거주하려는 의향이 있었지만 2013년 입주 시점에 가족들이 학업과 직장 문제로 서울에 남겠다는 뜻을 밝혔고 당시 노 후보자가 서울 왕래가 잦은 기획재정부 예산실 담당 국장이어서 세종에 살기 힘든 상황이었다고 설명했습니다\n",
      "-5.52 \n",
      " 국토부는 또 노 후보자가 2013년부터 4년간 전세를 주다가 2017년 문재인 정부 출범 이후 고위 공직자의 다주택 처분 권고에 따라 세종 아파트를 팔았다면서 시세 차익을 노린 투기는 아니었다고 해명했습니다\n",
      "-2.81 \n",
      " 또 향후 후보자는 현재 서울 서초구 반포동 아파트 한 채를 보유하고 있습니다\n",
      "7.20 \n",
      " 공정거래위원회가 확률형 아이템의 확률을 공개하지 않거나 속였다는 의혹을 받고 있는 넥슨코리아에 대한 현장조사에 착수했습니다\n",
      "-5.18 \n",
      " 공정위는 오늘 경기도 성남에 있는 넥슨코리아 본사에 조사관 10여 명을 보내 조사를 벌이고 있습니다\n",
      "6.58 \n",
      " 앞서 하태경 의원은 넥슨의 메이플스토리와 던져낸 파이터 마비노기 등이 전자상거래법을 위반했다며 조사를 의뢰한 바 있습니다\n",
      "7.83 \n",
      " 미 항공우주국 나사의 우주헬기가 화성의 하늘을 비행하는 데 성공했습니다\n",
      "-3.34 \n",
      " 지구 밖 행성에서 제어가 되는 동력체의 첫 비행이 성공하면서 우주 개척사의 새 장을 열었다는 평가입니다\n",
      "-5.45 \n",
      " 화성 표면에서 불과 3m 상공 단 30여 초간의 짧은 비행이었지만 지구가 아닌 행성에서 제어가 되는 동력체로서는 첫 비행이 성공하는 순간입니다\n",
      "-5.69 \n",
      " 미국 항공우주국 나사의 화성 탐사 우주헬기 인제니어티가 현지시간으로 19일 화성 하늘을 비행하는 데 성공했습니다\n",
      "-5.47 \n",
      " 지구에서 이 과정을 초조하게 지켜본 미국 항공우주국 나사 관계자들은 흥분을 감추지 못했습니다\n",
      "-5.55 \n",
      " 인제니어티는 지구에 비해 100분의 1에 불과한 화성의 대기 밀도는 물론 지구의 3분의 1인 중력 등을 고려해 제작됐습니다\n",
      "-6.03 \n",
      " 탄소섬유 재질의 날개로 일반 헬기보다 5배가량 빠르게 회전시켰습니다\n",
      "-6.89 \n",
      " 제작비용은 8500만 달러 약 950억 원가량이 투입됐는데 인제 뉴티는 앞으로 4차례 더 화성 상공을 시험 비행할 예정입니다\n",
      "5.22 \n",
      " 지구 이외의 행성에서 제어가 되는 동력체의 비행이 성공함으로써 우주탐사는 새로운 장을 열게 됐습니다\n",
      "0.68 \n",
      " 나사 관계자들은 화성 상공에서의 첫 동력 비행이 지난 1903년 라이트 형제의 동력 비행이 항공사의 새장을 연 것처럼 우주 개척의 새로운 이정표가 될 것으로 기대하고 있습니다\n",
      "8.33 \n",
      " 오세훈 서울시장은 오늘 서울시청에서 긴급 브리핑을 열고 전임 박원순 시장 시절 있었던 성희롱 성폭력 사건에 대해 사과했습니다\n",
      "-4.99 \n",
      " 오 시장은 또 피해자로부터 재조사 요청을 받은 사실을 공개하며 사건 재조사 방침도 밝혔습니다\n",
      "-4.76 \n",
      " 오 시장은 특히 서울시가 박 전 시장의 장례식을 서울시 기관장으로 치르면서 피해자는 절망할 수밖에 없었을 것이라며 당시 관련 책임자를 인사 조치했다고 말했습니다\n",
      "-4.56 \n",
      " 오 시장은 성폭력 사건에 대해 원스트라이크 아웃제를 즉시 도입하고 2차 피해에 대해서는 한 치의 관용조차 없을 것이라고 말했습니다\n",
      "1.75 \n",
      " 아무것도 아니야 최근 주한 벨기에 대사 부인이 옷가게 점원의 뺨을 때려 논란이 됐는데요\n",
      "-3.52 \n",
      " 당시 폭행 장면이 담긴 cctv 영상을 확보했습니다\n",
      "1.97 \n",
      " 면책 특권 때문에 처벌할 수 있을지 불투명한데 당사자는 경찰의 출석 요구에도 응하지 않고 있습니다\n",
      "4.38 \n",
      " 지난 9일 서울 용산구의 한 옷가게 한 여성이 들어와 옷을 입어봅니다\n",
      "-1.01 \n",
      " 피터 레스쿠이의 주한 벨기에 대사해 보인 A 씨입니다\n",
      "-4.93 \n",
      " A 씨가 옷가게를 둘러본 뒤 매장을 나서자 한 점원이 그 뒤를 쫓아갑니다\n",
      "-6.12 \n",
      " A 씨는 우연히 이 옷가게에서 판 옷과 똑같은 옷을 입고 있었는데 점원은 A씨가 옷을 입어본 뒤 돈을 안 내고 그냥 나간 걸로 오해한 겁니다\n",
      "-7.51 \n",
      " 점원이 옷가게로 돌아온 뒤 A씨도 매장으로 뒤따라와 해당 직원을 끌어내려 합니다\n",
      "-6.69 \n",
      " 말리던 다른 직원을 밀치고 뺨을 때리기도 했습니다\n",
      "-6.37 \n",
      " 신고를 받은 경찰이 도착해 가까스로 상황이 일단락됩니다\n",
      "-4.88 \n",
      " 피해 직원은 본인을 도둑 취급했다는 것에 분노한 것은 이해할 수 있지만 그렇다고 폭력이 정당화될 수는 없다고 kbs에 말했습니다\n",
      "명백한 폭행 사건으로 보이지만 처벌이 가능할지는 미지수입니다\n",
      "우리나라가 가입한 외교관계에 관한 비엔나 협약에 외교관의 가족은 주재국의 형사 재판을 받지 않는다고 규정돼 있어서입니다\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(script_list):\n",
    "    if (i >= ws) & (i <= len(script_list) - ws):\n",
    "        j = (i-ws)\n",
    "        print(f\"{score_list[j]:.2f}\", '\\n', sent)\n",
    "    else:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8.236818313598633,\n",
       " -8.497635841369629,\n",
       " -7.729971885681152,\n",
       " -7.541037559509277,\n",
       " -0.017026126384735107,\n",
       " -6.975645065307617,\n",
       " 0.946483314037323,\n",
       " 1.0367164611816406,\n",
       " -3.7296366691589355,\n",
       " -7.888616561889648,\n",
       " -0.2195427417755127,\n",
       " 3.6759793758392334,\n",
       " -5.857693672180176,\n",
       " -7.514585494995117,\n",
       " -5.989588737487793,\n",
       " -3.4307117462158203,\n",
       " 4.793019771575928,\n",
       " 5.50775671005249,\n",
       " 4.240488529205322,\n",
       " 7.416803359985352,\n",
       " 4.55340051651001,\n",
       " -8.771045684814453,\n",
       " -6.874622344970703]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = embedder.get_embeddings(test_article).transpose(1, 0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta_youtube",
   "language": "python",
   "name": "ta_youtube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
