{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRMM7am79f2L"
   },
   "source": [
    "#  자연어 처리를 위한 NLTK와 KoNLPy 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt  \n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "#okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7ZTOF0f9rxn"
   },
   "source": [
    "## NLTK와 NLTK Data 설치\n",
    "- 엔엘티케이(NLTK)는 자연어 처리를 위한 파이썬 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm1kjhqY9rV4",
    "outputId": "f5dffae8-092a-43a4-9bad-d9e707e2f08a"
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "s6ZaZ1W29rA-",
    "outputId": "4effcb3f-a63e-4e89-a752-959f93591922"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XEBrKXaD95i-"
   },
   "outputs": [],
   "source": [
    "# 해당 코드를 실행 후에 NLTK 실습에 필요한 각종 패키지와 코퍼스를 다운로드할 수 있다\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiB8SaeG-MF2"
   },
   "source": [
    "## KoNLPY 설치\n",
    "- 코엔엘파이(KoNLPy)는 한국어 자연어 처리를 위한 형태소 분석기 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQwCcSZ8-QhY",
    "outputId": "4b056a8f-54b2-41fa-a209-158fea5b6c78"
   },
   "outputs": [],
   "source": [
    "#!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RotHVV0F-T9K",
    "outputId": "a3ab0d41-510d-4aa3-ebc7-d534d3b62830"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import konlpy\n",
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 문장분류기(KSS : Korean Sentence Splitter) 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTWOh3lPBxHR",
    "outputId": "731763d2-fc32-4c67-dfe4-e771a1f2c9f2"
   },
   "outputs": [],
   "source": [
    "#! pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhtz-CBQ-hYb"
   },
   "source": [
    "# 텍스트 전처리\n",
    "- 토큰화 : 자연어 처리에서 크롤링 등으로 얻어낸 코퍼스 데이터가 필요에 맞게 전처리되지 않은 상태라면, 해당 데이터를 사용하고자하는 용도에 맞게 토큰화(tokenization) & 정제(cleaning) & 정규화(normalization)하는 일을 하게된다. 이렇듯 주어진 코퍼스에서 토큰이라 불리는 단위로 나눈 작업을 토큰화 작업이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB_Hk9b2_ZH1"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "735k2D9_u4tH",
    "outputId": "17dc6702-4366-4f46-e7a6-34298b3379d7"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'bash\\ncd /tmp\\ngit clone https://bitbucket.org/eunjeon/mecab-python-0.996.git\\ncd mecab-python-0.996\\npython3 setup.py build\\npython3 setup.py install\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# mecab - 방법1\n",
    "# https://sosomemo.tistory.com/30\n",
    "# Mecab설치\n",
    "'''bash\n",
    "cd /tmp\n",
    "sudo wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
    "sudo tar xvf mecab-0.996-ko-0.9.2.tar.gz\n",
    "\n",
    "cd /tmp/mecab-0.996-ko-0.9.2\n",
    "sudo ./configure\n",
    "sudo make check\n",
    "sudo make install\n",
    "'''\n",
    "\n",
    "'''bash\n",
    "cd /tmp\n",
    "wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "tar zxvf mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "\n",
    "cd /tmp/mecab-ko-dic-2.1.1-20180720\n",
    "sudo ./autogen.sh\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\n",
    "'''\n",
    "\n",
    "'''bash\n",
    "cd /tmp\n",
    "git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git\n",
    "cd mecab-python-0.996\n",
    "python3 setup.py build\n",
    "python3 setup.py install\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sa7uhkEGAA9a"
   },
   "source": [
    "**Word2Vec의 하이퍼파라미터 값**\n",
    "\n",
    "- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.  \n",
    "- window = 컨텍스트 윈도우 크기  \n",
    "- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)  \n",
    "- workers = 학습을 위한 프로세스 수  \n",
    "- sg = 0은 CBOW, 1은 Skip-gram.  "
   ]
  },
  {
   "source": [
    "## Ko-Wiki Data 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ko_wiki_path = '/repo/course/sem21_01/youtube_summarizer/dataset/preprocessed/'\n",
    "ko_wiki_txt = open(ko_wiki_path+'processed_wiki_ko.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_wiki_para = ko_wiki_txt.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "311237"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(ko_wiki_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'제임스 얼 \"지미\" 카터 주니어 (, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ 1981년)이다. 지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다. 조지아 공과대학교를 졸업하였다. 그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다. 1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다. 그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다. 1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다. 대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다. 조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다. 취임식을 올리는 카터 1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다. 카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다. Carter Begin, Camp David 1978.gif|섬네일|300px|캠프데이비드에서 사다트와 베긴과 함께카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다. 그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다. 1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다. 또한 소련과 제2차 전략 무기 제한 협상에 조인했다. 카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다. 그러나 주 이란 미국 대사관 인질 사건에서 인질 구출 실패를 이유로 1980년 대통령 선거에서 공화당의 로널드 레이건 후보에게 져 결국 재선에 실패했다. 또한 임기 말기에 터진 소련의 아프가니스탄 침공 사건으로 인해 1980년 하계 올림픽에 반공국가들의 보이콧을 내세웠다. 지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다. 인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다. 1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다. 그러나 주한미군사령부와 정보기관·의회의 반대에 부딪혀 주한미군은 완전철수 대신 6,000명을 감축하는 데 그쳤다 . 또한 박정희 정권의 인권 문제 등과의 논란으로 불협화음을 냈으나, 1979년 6월 하순, 대한민국을 방문하여 관계가 다소 회복되었다. 1979년 ~ 1980년 대한민국의 정치적 격변기 당시의 대통령이었던 그는 이에 대해 애매한 태도를 보였고, 이는 후에 대한민국 내에서 고조되는 반미 운동의 한 원인이 됐다. 10월 26일, 박정희 대통령이 김재규 중앙정보부장에 의해 살해된 것에 대해 그는 이 사건으로 큰 충격을 받았으며, 사이러스 밴스 국무장관을 조문사절로 파견했다. 12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다. 남수단 독립 국민투표에 업저버 사절단을 지도한 카터 퇴임 이후 민간 자원을 적극 활용한 비영리 기구인 카터 재단을 설립한 뒤 민주주의 실현을 위해 제 3세계의 선거 감시 활동 및 기니 벌레에 의한 드라쿤쿠르스 질병 방재를 위해 힘썼다. 미국의 빈곤층 지원 활동, 사랑의 집짓기 운동, 국제 분쟁 중재 등의 활동도 했다. 카터는 카터 행정부 이후 미국이 북핵 위기, 코소보 전쟁, 이라크 전쟁과 같이 미국이 군사적 행동을 최후로 선택하는 전통적 사고를 버리고 군사적 행동을 선행하는 행위에 대해 깊은 유감을 표시 하며 미국의 군사적 활동에 강한 반대 입장을 보이고 있다. 특히 국제 분쟁 조정을 위해 북한의 김일성, 아이티의 세드라스 장군, 팔레인스타인의 하마스, 보스니아의 세르비아계 정권 같이 미국 정부에 대해 협상을 거부하면서 사태의 위기를 초래한 인물 및 단체를 직접 만나 분쟁의 원인을 근본적으로 해결하기 위해 힘썼다. 이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다. 1978년에 채결된 캠프데이비드 협정의 이행이 지지부진 하자 중동 분쟁 분제를 해결하기 위해 1993년 퇴임 후 직접 이스라엘과 팔레인스타인의 오슬로 협정을 이끌어 내는 데도 성공했다. 행렬 50주년을 맞는 날 빌 클린턴, 버락 오바마 대통령과 함께 (2013년) 1993년 1차 북핵 위기 당시 북한에 대한 미국의 군사적 행동이 임박했으나, 미국 전직 대통령으로는 처음으로 북한을 방문하고 미국과 북 양국의 중재에 큰 기여를 해 위기를 해결했다는 평가를 받았다. 또한 이 때 김영삼 대통령과 김일성 주석의 만남을 주선했다. 하지만 그로부터 수주일 후 김일성이 갑자기 사망하여 김일성과 김영삼의 정상회담은 이루어지지 못했다. 미국의 관타나모 수용소 문제, 세계의 인권문제에서도 관심이 깊어 유엔에 유엔인권고등판무관의 제도를 시행하도록 노력하여 독재자들의 인권 유린에 대해 제약을 하고, 국제형사재판소를 만드는 데 기여하여 독재자들 같은 인권유린범죄자를 재판소로 회부하여 국제적인 처벌을 받게 하는 등 인권 신장에 크나 큰 기여를 했다. 2011년 4월 26일부터 29일까지 북한을 3일간 방문했다. 경제문제를 해결하지 못하고 주 이란 미국 대사관 인질 사건에 발목이 잡혀 실패한 대통령으로 평가를 받지만 이란 사태는 미국 내 이란 재산을 풀어주겠다는 조건을 내세워서 사실상 카터가 해결한 것이었고, 사랑의 집짓기 운동 등으로 퇴임 후에 훨씬 더 존경받는 미국 대통령 중에 특이한 인물로 남았다. 그는 2002년 말 인권과 중재 역할에 대한 공로를 인정받아 노벨 평화상을 받게 되었다. 《진정한 리더는 떠난 후에 아름답다》 저자 지미 카터 《지미 카터》 저자 지미 카터(지식의날개, 2018) 분류:1924년 태어남 분류:1976년 미국 대통령 후보 분류:1980년 미국 대통령 후보 분류:그래미상 수상자 분류:노벨 평화상 수상자 분류:미국 해군의 장교 분류:미국의 침례교도 분류:미국의 노벨상 수상자 분류:미국의 농부 분류:미국의 대통령 분류:미국의 역사 (1964-1980) 분류:미국의 외교관 분류:미국의 인도주의자 분류:미국의 제2차 세계 대전 참전 군인 분류:미국의 진보주의 분류:민주당 (미국)의 정치인 분류:살아있는 사람 분류:스코틀랜드계 미국인 분류:아일랜드계 미국인 분류:잉글랜드계 미국인 분류:조지아 공과대학교 동문 분류:조지아주 출신 정치인 분류:조지아주지사 분류:미국의 회고록 작가 분류:에모리 대학교 교수 분류:미국 해군사관학교 동문 분류:미국 미주리 종합군사학원 동문 분류:타임 올해의 인물 분류:군사 기술자 분류:이란 혁명 관련자\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "ko_wiki_para[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['제임스 얼 \"지미\" 카터 주니어 (, 1924년 10월 1일 ~ )는 민주당 출신 미국 39번째 대통령 (1977년 ~ 1981년)이다.', '지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.', '조지아 공과대학교를 졸업하였다.', '그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다.', '1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다.', '그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.', '1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다.', '대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다.', '조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.', '취임식을 올리는 카터 1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다.', '카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.', 'Carter Begin, Camp David 1978.gif|섬네일|300px|캠프데이비드에서 사다트와 베긴과 함께카터는 이집트와 이스라엘을 조정하여, 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다.', '그러나 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다.', '1979년 백악관에서 양국 간의 평화조약으로 이끌어졌다.', '또한 소련과 제2차 전략 무기 제한 협상에 조인했다.', '카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.', '그러나 주 이란 미국 대사관 인질 사건에서 인질 구출 실패를 이유로 1980년 대통령 선거에서 공화당의 로널드 레이건 후보에게 져 결국 재선에 실패했다.', '또한 임기 말기에 터진 소련의 아프가니스탄 침공 사건으로 인해 1980년 하계 올림픽에 반공국가들의 보이콧을 내세웠다.', '지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다.', '인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다.', '1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다.', '그러나 주한미군사령부와 정보기관·의회의 반대에 부딪혀 주한미군은 완전철수 대신 6,000명을 감축하는 데 그쳤다 .', '또한 박정희 정권의 인권 문제 등과의 논란으로 불협화음을 냈으나, 1979년 6월 하순, 대한민국을 방문하여 관계가 다소 회복되었다.', '1979년 ~ 1980년 대한민국의 정치적 격변기 당시의 대통령이었던 그는 이에 대해 애매한 태도를 보였고, 이는 후에 대한민국 내에서 고조되는 반미 운동의 한 원인이 됐다.', '10월 26일, 박정희 대통령이 김재규 중앙정보부장에 의해 살해된 것에 대해 그는 이 사건으로 큰 충격을 받았으며, 사이러스 밴스 국무장관을 조문사절로 파견했다.', '12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다.', '남수단 독립 국민투표에 업저버 사절단을 지도한 카터 퇴임 이후 민간 자원을 적극 활용한 비영리 기구인 카터 재단을 설립한 뒤 민주주의 실현을 위해 제 3세계의 선거 감시 활동 및 기니 벌레에 의한 드라쿤쿠르스 질병 방재를 위해 힘썼다.', '미국의 빈곤층 지원 활동, 사랑의 집짓기 운동, 국제 분쟁 중재 등의 활동도 했다.', '카터는 카터 행정부 이후 미국이 북핵 위기, 코소보 전쟁, 이라크 전쟁과 같이 미국이 군사적 행동을 최후로 선택하는 전통적 사고를 버리고 군사적 행동을 선행하는 행위에 대해 깊은 유감을 표시 하며 미국의 군사적 활동에 강한 반대 입장을 보이고 있다.', '특히 국제 분쟁 조정을 위해 북한의 김일성, 아이티의 세드라스 장군, 팔레인스타인의 하마스, 보스니아의 세르비아계 정권 같이 미국 정부에 대해 협상을 거부하면서 사태의 위기를 초래한 인물 및 단체를 직접 만나 분쟁의 원인을 근본적으로 해결하기 위해 힘썼다.', '이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다.', '1978년에 채결된 캠프데이비드 협정의 이행이 지지부진 하자 중동 분쟁 분제를 해결하기 위해 1993년 퇴임 후 직접 이스라엘과 팔레인스타인의 오슬로 협정을 이끌어 내는 데도 성공했다.', '행렬 50주년을 맞는 날 빌 클린턴, 버락 오바마 대통령과 함께 (2013년) 1993년 1차 북핵 위기 당시 북한에 대한 미국의 군사적 행동이 임박했으나, 미국 전직 대통령으로는 처음으로 북한을 방문하고 미국과 북 양국의 중재에 큰 기여를 해 위기를 해결했다는 평가를 받았다.', '또한 이 때 김영삼 대통령과 김일성 주석의 만남을 주선했다.', '하지만 그로부터 수주일 후 김일성이 갑자기 사망하여 김일성과 김영삼의 정상회담은 이루어지지 못했다.', '미국의 관타나모 수용소 문제, 세계의 인권문제에서도 관심이 깊어 유엔에 유엔인권고등판무관의 제도를 시행하도록 노력하여 독재자들의 인권 유린에 대해 제약을 하고, 국제형사재판소를 만드는 데 기여하여 독재자들 같은 인권유린범죄자를 재판소로 회부하여 국제적인 처벌을 받게 하는 등 인권 신장에 크나 큰 기여를 했다.', '2011년 4월 26일부터 29일까지 북한을 3일간 방문했다.', '경제문제를 해결하지 못하고 주 이란 미국 대사관 인질 사건에 발목이 잡혀 실패한 대통령으로 평가를 받지만 이란 사태는 미국 내 이란 재산을 풀어주겠다는 조건을 내세워서 사실상 카터가 해결한 것이었고, 사랑의 집짓기 운동 등으로 퇴임 후에 훨씬 더 존경받는 미국 대통령 중에 특이한 인물로 남았다.', '그는 2002년 말 인권과 중재 역할에 대한 공로를 인정받아 노벨 평화상을 받게 되었다.', '《진정한 리더는 떠난 후에 아름답다》 저자 지미 카터 《지미 카터》 저자 지미 카터(지식의날개, 2018) 분류:1924년 태어남 분류:1976년 미국 대통령 후보 분류:1980년 미국 대통령 후보 분류:그래미상 수상자 분류:노벨 평화상 수상자 분류:미국 해군의 장교 분류:미국의 침례교도 분류:미국의 노벨상 수상자 분류:미국의 농부 분류:미국의 대통령 분류:미국의 역사 (1964-1980) 분류:미국의 외교관 분류:미국의 인도주의자 분류:미국의 제2차 세계 대전 참전 군인 분류:미국의 진보주의 분류:민주당 (미국)의 정치인 분류:살아있는 사람 분류:스코틀랜드계 미국인 분류:아일랜드계 미국인 분류:잉글랜드계 미국인 분류:조지아 공과대학교 동문 분류:조지아주 출신 정치인 분류:조지아주지사 분류:미국의 회고록 작가 분류:에모리 대학교 교수 분류:미국 해군사관학교 동문 분류:미국 미주리 종합군사학원 동문 분류:타임 올해의 인물 분류:군사 기술자 분류:이란 혁명 관련자']\n"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "\n",
    "para1 = ko_wiki_para[0]\n",
    "\n",
    "print(kss.split_sentences(para1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## multi-processing\n",
    "# points_images = [[points_lst[i], images[i]] for i in range(len(images))]\n",
    "# with Pool(workers or cpu_count()) as pool:\n",
    "# result = list(tqdm(pool.imap(\n",
    "#     func=partial(getFeatureDesriptors_, winSize=winSize, num_bins=num_bins),\n",
    "#     iterable=points_images), total=len(points_images)))\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "# return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','은','는','이','가','좀','잘','과','도','을','를','으로','자','에','와','한','하다','합니다', '입니다','습니다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 311237/311237 [2:51:38<00:00, 30.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_wiki_data = []\n",
    "for para in tqdm(ko_wiki_para):\n",
    "    para = kss.split_sentences(para) # split sentence\n",
    "    for sentence in para:\n",
    "        #print(f'previous : {sentence}')\n",
    "        tmp_sen = re.sub('[^가-힣a-z]', ' ', sentence) # 영어 소문자와 한글을 제외한 모든 문자를 제거\n",
    "        temp_X = mecab.morphs(tmp_sen) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        #print(f'after : {temp_X}')\n",
    "        tokenized_wiki_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/tokenized_dataset/tokenized_wiki_data.pkl'\n",
    "\n",
    "# save pickle file\n",
    "with open(pk_path, 'wb') as f:\n",
    "    pickle.dump(tokenized_wiki_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/tokenized_dataset/tokenized_wiki_data.pkl'\n",
    "\n",
    "# load pickle file\n",
    "with open(pk_path, 'rb') as f:\n",
    "     tokenized_wiki_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srvblMW4AOcd"
   },
   "source": [
    "## 뉴스 기사 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QVTI-34CATWb"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/repo/course/sem21_01/youtube_summarizer/jupyter'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "FIdK1h5Gpb4C",
    "outputId": "9b5a7a44-de45-45db-a267-32ed4db70228"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape : (260697, 5)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  media         id                                   article_original  \\\n",
       "0  부산일보  360972161  [지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...   \n",
       "1  중도일보  356659913  [서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...   \n",
       "2  무등일보  351718460  [지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...   \n",
       "3  이데일리  335868123  [서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...   \n",
       "4  서울신문  351443347  [미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...   \n",
       "\n",
       "                                         abstractive   extractive  \n",
       "0  통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...  [4, 11, 18]  \n",
       "1  서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...    [1, 3, 4]  \n",
       "2   ‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...    [0, 2, 4]  \n",
       "3  서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...    [0, 1, 2]  \n",
       "4  미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...    [0, 1, 2]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>media</th>\n      <th>id</th>\n      <th>article_original</th>\n      <th>abstractive</th>\n      <th>extractive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>부산일보</td>\n      <td>360972161</td>\n      <td>[지난해 고령화와 유례가 드문 겨울 한파 등 영향으로 우리나라 사망자 수가 통계 작...</td>\n      <td>통계청이 발표한 '2018년 사망원인통계'를 보면 지난해 총 사망자 수는 관련 통계...</td>\n      <td>[4, 11, 18]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>중도일보</td>\n      <td>356659913</td>\n      <td>[서산시의회(의장 임재관) 가충순·이수의 의원이 (사)한국지역신문협회에서 수여하는 ...</td>\n      <td>서산시 가충순 의원과 이수의 의원이 활발한 의정활동을 펼친 감사의 표시로 한국지역신...</td>\n      <td>[1, 3, 4]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>무등일보</td>\n      <td>351718460</td>\n      <td>[지난 2004년 시작해 조선대 학생들의 대표적인 행사로 자리매김한 ‘조선대 국토대...</td>\n      <td>‘조선대의 새로운 비상을 꿈꾸다’를 슬로건으로 진행되어 단체생활을 통해 협동심과 ...</td>\n      <td>[0, 2, 4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>이데일리</td>\n      <td>335868123</td>\n      <td>[서울시는 신학기가 시작되는 다음달 4일부터 고등학교 3학년 무상급식을 실시한다고 ...</td>\n      <td>서울시가 다음달 4일부터 서울 시내 319개 고등학교 3학년 8만4700명을 대상으...</td>\n      <td>[0, 1, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>서울신문</td>\n      <td>351443347</td>\n      <td>[미국인 선교사가 우간다에서 의사 행세를 하며 의료 시설을 운영한 혐의로 지역 시민...</td>\n      <td>미국인 선교사가 우간다에서 의사 행세를 하며 두 아이의 죽음과 관련돼 있다며 지역 ...</td>\n      <td>[0, 1, 2]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path = '/repo/course/sem21_01/youtube_summarizer/dataset/article_dataset/train.jsonl'\n",
    "\n",
    "### bfly train\n",
    "sent_df = pd.read_json(path, lines=True, encoding=\"utf-8\")\n",
    "print('shape : {}'.format(sent_df.shape))\n",
    "sent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mULhS6PUrPGY"
   },
   "outputs": [],
   "source": [
    "#from konlpy.tag import Okt  \n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "#okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "nToHnaxIGU29"
   },
   "outputs": [],
   "source": [
    "stopwords = ['은','는','이','가','의','좀','잘','과','도','을','를','으로','자','에','와','한','하다','합니다','이다','입니다','습니다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "SWfeawS4NsqC"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "fjsut73Q8szP"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 260697/260697 [08:58<00:00, 483.90it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_news_data = []\n",
    "for news in tqdm(sent_df['article_original']):\n",
    "    for sentence in news:\n",
    "        #print(f'previous : {sentence}')\n",
    "        tmp_sen = re.sub('[^가-힣a-z]', ' ', sentence) # 영어 소문자와 한글을 제외한 모든 문자를 제거\n",
    "        temp_X = mecab.morphs(tmp_sen) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        #print(f'after : {temp_X}')\n",
    "        tokenized_news_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "63Y7RVuEr0kN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/tokenized_dataset/tokenized_news_data.pkl'\n",
    "\n",
    "# save pickle file\n",
    "with open(pk_path, 'wb') as f:\n",
    "    pickle.dump(tokenized_news_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pk_path = '/repo/course/sem21_01/youtube_summarizer/dataset/tokenized_dataset/tokenized_news_data.pkl'\n",
    "\n",
    "# load pickle file\n",
    "with open(pk_path, 'rb') as f:\n",
    "     tokenized_news_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['지난해',\n",
       " '고령화',\n",
       " '유례',\n",
       " '드문',\n",
       " '겨울',\n",
       " '한파',\n",
       " '등',\n",
       " '영향',\n",
       " '우리나라',\n",
       " '사망자',\n",
       " '수',\n",
       " '통계',\n",
       " '작성',\n",
       " '이후',\n",
       " '가장',\n",
       " '많',\n",
       " '았',\n",
       " '다']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "tokenized_news_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['제임스',\n",
       " '얼',\n",
       " '지미',\n",
       " '카터',\n",
       " '주니어',\n",
       " '년',\n",
       " '월',\n",
       " '일',\n",
       " '민주당',\n",
       " '출신',\n",
       " '미국',\n",
       " '번',\n",
       " '째',\n",
       " '대통령',\n",
       " '년',\n",
       " '년',\n",
       " '다']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tokenized_wiki_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh41lNSUI64T"
   },
   "source": [
    "### import pretrained model (사용 X))\n",
    "**Pretraining 환경**\n",
    "~~~\n",
    "def train_word2vec(corpus_fname, model_fname):\n",
    "    make_save_path(model_fname)\n",
    "    corpus = Word2VecCorpus(corpus_fname)\n",
    "    model = Word2Vec(corpus, size=100, workers=4, sg=1)\n",
    "    model.save(model_fname)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3965859"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "len(tokenized_wiki_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3300370"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "len(tokenized_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7266229"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "train_w2v.extend(tokenized_wiki_data)\n",
    "train_w2v.extend(tokenized_news_data)\n",
    "len(train_w2v)"
   ]
  },
  {
   "source": [
    "### Train New Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# FastText\n",
    "from gensim.models import FastText\n",
    "'''\n",
    "sentences (iterable of iterables, optional) – The sentences iterable can be simply a list of lists of tokens, but for larger corpora, consider an iterable that streams the sentences directly from disk/network. See BrownCorpus, Text8Corpus or LineSentence in word2vec module for such examples. See also the tutorial on data streaming in Python. If you don’t supply sentences, the model is left uninitialized – use if you plan to initialize it in some other way.\n",
    "\n",
    "size (int, optional) – Dimensionality of the word vectors.\n",
    "\n",
    "window (int, optional) – Maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "min_count (int, optional) – Ignores all words with total frequency lower than this.\n",
    "\n",
    "workers (int, optional) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
    "'''\n",
    "\n",
    "w2v_model = Word2Vec(sentences = train_w2v, size = 768, window = 5, workers = 7, sg = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_path = '/repo/course/sem21_01/youtube_summarizer/src/word_embedding/model/'\n",
    "\n",
    "w2v_model.save(w2v_path+'w2v_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f048012c470>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model_test = Word2Vec.load(w2v_path+'w2v_model.model')\n",
    "\n",
    "w2v_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('고양이', 0.5076916813850403), ('애완견', 0.49656134843826294), ('애견', 0.4751525819301605), ('반려', 0.46863648295402527), ('애견인', 0.4465317726135254), ('견', 0.44478684663772583), ('펫', 0.43852585554122925), ('동물', 0.4298151135444641), ('키워본', 0.42482659220695496), ('폭스테리어', 0.42475879192352295)]\n"
     ]
    }
   ],
   "source": [
    "result=w2v_model_test.wv.most_similar(\"강아지\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "finetuned_wv.save(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/finetuned_wv.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_word_vectors = KeyedVectors.load(\"/repo/course/sem21_01/youtube_summarizer/dataset/pretrained_word2vec/finetuned_wv.kv\")\n",
    "reloaded_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_word_vectors[\"안녕\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_word_vectors.get_vector(\"안녕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "O4QYT3BVK64Z",
    "c8R2EM1wHtLm"
   ],
   "machine_shape": "hm",
   "name": "자연어 전처리_실험.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}