{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)s [%(levelname)s] %(message)s\", \n",
    "                    level=logging.INFO,\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(os.path.join(\"./subtext_test_result.log\")),\n",
    "                        logging.StreamHandler()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call model (BertSum/SubtextDivider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) BertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 추가\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/bertsum')\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/subtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:47,033 [INFO] PyTorch version 1.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from models.data_loader import TextLoader, load_dataset\n",
    "from src.backbone import ExtTransformerEncoder, ExtSummarizer, WindowEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"visible_gpus\" : -1,\n",
    "    \"temp_dir\" : './tmp/',\n",
    "    \"test_from\": None,\n",
    "    \"max_pos\" : 512,\n",
    "    \"large\" : False,\n",
    "    \"finetune_bert\": True,\n",
    "    \"encoder\": \"bert\",\n",
    "    \"share_emb\": False,\n",
    "    \"dec_layers\": 6,\n",
    "    \"dec_dropout\": 0.2,\n",
    "    \"dec_hidden_size\": 768,\n",
    "    \"dec_heads\": 8,\n",
    "    \"dec_ff_size\": 2048,\n",
    "    \"enc_hidden_size\": 512,\n",
    "    \"enc_ff_size\": 512,\n",
    "    \"enc_dropout\": 0.2,\n",
    "    \"enc_layers\": 6,\n",
    "    \n",
    "    \"ext_dropout\": 0.2,\n",
    "    \"ext_layers\": 2,\n",
    "    \"ext_hidden_size\": 768,\n",
    "    \"ext_heads\": 8,\n",
    "    \"ext_ff_size\": 2048,\n",
    "    \n",
    "    \"accum_count\": 1,\n",
    "    \"save_checkpoint_steps\": 5,\n",
    "    \n",
    "    \"generator_shard_size\": 32,\n",
    "    \"alpha\": 0.6,\n",
    "    \"beam_size\": 5,\n",
    "    \"min_length\": 15,\n",
    "    \"max_length\": 150,\n",
    "    \"max_tgt_len\": 140,  \n",
    "    \"block_trigram\": True,\n",
    "    \n",
    "    \"model_path\": \"./tmp_model/\",\n",
    "    \"result_path\": \"./tmp_result/src\",\n",
    "    \"recall_eval\": False,\n",
    "    \"report_every\": 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:58,074 [INFO] loading configuration file ./tmp/kobert_from_pretrained/config.json\n",
      "2021-05-07 01:07:58,077 [INFO] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "2021-05-07 01:07:58,079 [INFO] loading weights file ./tmp/kobert_from_pretrained/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:59,349 [INFO] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "2021-05-07 01:07:59,350 [INFO] All the weights of BertModel were initialized from the model checkpoint at ./tmp/kobert_from_pretrained.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtSummarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(8004, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ext_layer): ExtTransformerEncoder(\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (transformer_inter): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "device = \"cpu\" if args.visible_gpus == -1 else \"cuda\"\n",
    "loader = TextLoader(args, device)\n",
    "\n",
    "# model setting\n",
    "ckpt_path = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/bertsum/checkpoint/model_step_24000.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "bert_model = ExtSummarizer(args, device, checkpoint)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = WindowEmbedder(model=bert_model, text_loader=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) SubtextDivider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubtextClassifier(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv1d(768, 128, kernel_size=(4,), stride=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.subtext_classifier import SubtextClassifier\n",
    "\n",
    "subtext_model = SubtextClassifier(window_size=3).cuda()\n",
    "\n",
    "model_path = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/subtext/ckpt/subtext_model_w3_fixed.pt'\n",
    "subtext_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "subtext_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Score Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divscore(src_doc=[], embedder=None, divider=None):\n",
    "    embedding = embedder.get_embeddings(src_doc).transpose(1, 0).unsqueeze(0)\n",
    "    score = divider(embedding).item()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 260697 records from /home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/article_dataset/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "news_df = load_jsonl('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/article_dataset/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# (1) 글자 개수가 너무 작은 경우 없애기 (30글자 이상)\n",
    "# (2) 문장이 적은 경우 해당 기사 없애기 (10문장 이상)\n",
    "news_clean = []\n",
    "for news in news_df:\n",
    "    news_article = news['article_original']\n",
    "    if len(news_article) >= 10:\n",
    "        article_clean = [sent for sent in news_article if len(sent) >= 30]\n",
    "        news_clean.append(article_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_mixed_doc(news_dataset=None, max_num=1000):\n",
    "    mixed_doc_set = []\n",
    "    for i in range(max_num):\n",
    "        lh_count = min(random.randint(7, 10), len(news_dataset[i]))\n",
    "        rh_count = min(random.randint(7, 10), len(news_dataset[i+1]))\n",
    "\n",
    "        lh_news = news_dataset[i][:lh_count]\n",
    "        rh_news = news_dataset[i+1][:rh_count]\n",
    "        \n",
    "        gt = lh_count - 1\n",
    "\n",
    "        src_doc = '\\n'.join((lh_news + rh_news))\n",
    "        mixed_doc_set.append((src_doc, gt))\n",
    "        \n",
    "    return mixed_doc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020011135)\n",
    "mixed_doc_list = make_mixed_doc(news_dataset=news_clean, max_num=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "loader = TextLoader(args, device)\n",
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:57:07,751 [INFO] working on 20th doc: Accuracy so far is 73.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 30th article\n",
      "Error occurred at 32th article\n",
      "Error occurred at 33th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:57:52,749 [INFO] working on 40th doc: Accuracy so far is 77.78%\n",
      "2021-05-02 19:58:43,279 [INFO] working on 60th doc: Accuracy so far is 80.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 66th article\n",
      "Error occurred at 67th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:59:27,099 [INFO] working on 80th doc: Accuracy so far is 75.68%\n",
      "2021-05-02 20:00:19,010 [INFO] working on 100th doc: Accuracy so far is 79.79%\n",
      "2021-05-02 20:01:05,288 [INFO] working on 120th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:01:53,274 [INFO] working on 140th doc: Accuracy so far is 78.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 156th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:02:39,330 [INFO] working on 160th doc: Accuracy so far is 79.74%\n",
      "2021-05-02 20:03:28,138 [INFO] working on 180th doc: Accuracy so far is 79.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 191th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:04:10,577 [INFO] working on 200th doc: Accuracy so far is 80.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 206th article\n",
      "Error occurred at 207th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:04:55,522 [INFO] working on 220th doc: Accuracy so far is 80.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 221th article\n",
      "Error occurred at 222th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:05:41,893 [INFO] working on 240th doc: Accuracy so far is 79.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 248th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:06:30,241 [INFO] working on 260th doc: Accuracy so far is 79.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 265th article\n",
      "Error occurred at 266th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:07:16,536 [INFO] working on 280th doc: Accuracy so far is 78.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 291th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:08:05,110 [INFO] working on 300th doc: Accuracy so far is 76.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 300th article\n",
      "Error occurred at 312th article\n",
      "Error occurred at 315th article\n",
      "Error occurred at 316th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:08:52,520 [INFO] working on 320th doc: Accuracy so far is 77.33%\n",
      "2021-05-02 20:09:38,502 [INFO] working on 340th doc: Accuracy so far is 77.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 338th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:10:25,756 [INFO] working on 360th doc: Accuracy so far is 77.29%\n",
      "2021-05-02 20:11:14,110 [INFO] working on 380th doc: Accuracy so far is 77.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 387th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:12:00,515 [INFO] working on 400th doc: Accuracy so far is 77.25%\n",
      "2021-05-02 20:12:48,850 [INFO] working on 420th doc: Accuracy so far is 77.89%\n",
      "2021-05-02 20:13:37,001 [INFO] working on 440th doc: Accuracy so far is 78.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 446th article\n",
      "Error occurred at 447th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:14:19,661 [INFO] working on 460th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:15:05,472 [INFO] working on 480th doc: Accuracy so far is 79.39%\n",
      "2021-05-02 20:15:58,735 [INFO] working on 500th doc: Accuracy so far is 79.41%\n",
      "2021-05-02 20:16:53,206 [INFO] working on 520th doc: Accuracy so far is 79.84%\n",
      "2021-05-02 20:17:42,199 [INFO] working on 540th doc: Accuracy so far is 79.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 546th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:18:28,825 [INFO] working on 560th doc: Accuracy so far is 79.63%\n",
      "2021-05-02 20:19:19,594 [INFO] working on 580th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:20:10,408 [INFO] working on 600th doc: Accuracy so far is 80.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 599th article\n",
      "Error occurred at 600th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:20:55,960 [INFO] working on 620th doc: Accuracy so far is 79.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 631th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:21:42,848 [INFO] working on 640th doc: Accuracy so far is 80.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 641th article\n",
      "Error occurred at 648th article\n",
      "Error occurred at 649th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:22:23,885 [INFO] working on 660th doc: Accuracy so far is 80.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 663th article\n",
      "Error occurred at 664th article\n",
      "Error occurred at 667th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:23:05,795 [INFO] working on 680th doc: Accuracy so far is 80.50%\n",
      "2021-05-02 20:23:52,135 [INFO] working on 700th doc: Accuracy so far is 80.33%\n",
      "2021-05-02 20:24:43,570 [INFO] working on 720th doc: Accuracy so far is 80.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 726th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:25:32,328 [INFO] working on 740th doc: Accuracy so far is 80.57%\n",
      "2021-05-02 20:26:20,843 [INFO] working on 760th doc: Accuracy so far is 80.28%\n",
      "2021-05-02 20:27:06,800 [INFO] working on 780th doc: Accuracy so far is 80.54%\n",
      "2021-05-02 20:27:59,666 [INFO] working on 800th doc: Accuracy so far is 80.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 798th article\n",
      "Error occurred at 801th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:28:44,063 [INFO] working on 820th doc: Accuracy so far is 80.46%\n",
      "2021-05-02 20:29:38,363 [INFO] working on 840th doc: Accuracy so far is 80.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 854th article\n",
      "Error occurred at 855th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:30:22,763 [INFO] working on 860th doc: Accuracy so far is 80.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 869th article\n",
      "Error occurred at 870th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:31:04,383 [INFO] working on 880th doc: Accuracy so far is 80.33%\n",
      "2021-05-02 20:31:47,949 [INFO] working on 900th doc: Accuracy so far is 79.98%\n",
      "2021-05-02 20:32:33,937 [INFO] working on 920th doc: Accuracy so far is 79.64%\n",
      "2021-05-02 20:33:25,227 [INFO] working on 940th doc: Accuracy so far is 79.76%\n",
      "2021-05-02 20:34:13,123 [INFO] working on 960th doc: Accuracy so far is 79.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 967th article\n",
      "Error occurred at 968th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:34:59,979 [INFO] working on 980th doc: Accuracy so far is 79.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 983th article\n",
      "Error occurred at 984th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:35:49,014 [INFO] working on 1000th doc: Accuracy so far is 79.27%\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "acc_cnt = 0\n",
    "ws = 3\n",
    "\n",
    "div_result = []\n",
    "for i, a_set in enumerate(mixed_doc_list):\n",
    "    \n",
    "    if (i+1) % 20 == 0:\n",
    "        logger.info(f\"working on {i+1}th doc: Accuracy so far is {acc_cnt/(acc_cnt+err_cnt)*100:.2f}%\")\n",
    "        \n",
    "    src_doc = a_set[0].split('\\n')\n",
    "    gt = a_set[1]\n",
    "    \n",
    "    cands = [src_doc[i:i+ws*2] for i, _ in enumerate(src_doc) if i <= len(src_doc) - ws*2]\n",
    "    \n",
    "    # 가끔 한문장이 너무길어서 잘리는 경우가 있음..\n",
    "    try:\n",
    "        div_scores = [get_divscore(src_doc=cand, embedder=embedder, divider=subtext_model) for cand in cands]\n",
    "        div_point = div_scores.index(max(div_scores)) + ws - 1\n",
    "\n",
    "        if div_point == gt:\n",
    "            acc_cnt += 1\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error occurred at {i}th article\")\n",
    "    \n",
    "#     sents = [sent for sent in src_doc.split('\\n') if sent]\n",
    "#     lh_sent, rh_sent = [], []\n",
    "#     for i, sent in enumerate(sents):\n",
    "#         if i <= div_point:\n",
    "#             lh_sent.append(sent)\n",
    "#         else:\n",
    "#             rh_sent.append(sent)\n",
    "            \n",
    "#     result_sents = lh_sent + [\"----------------[DIV]---------------\"] + rh_sent\n",
    "#     div_result.append((result_sents, div_scores, div_point, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91636c8cdc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{acc_cnt / (acc_cnt + err_cnt)*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_cnt' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{acc_cnt / (acc_cnt + err_cnt)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 기사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_list = mixed_doc_list[35][0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[충청일보 이정규기자] 폐원을 신청한 청주 은성유치원이 충북도교육감을 상대로 낸 행정소송을 취하하려했지만 도교육청이 이를 거부한 것으로 전해졌다.',\n",
       " \"6일 충북도교육청에 따르면 은성유치원은 지난 2017년 7월 도교육감을 상대로 '징계의결 요구 처분 취소' 청구소송을 낸 후 지난해 12월 27일 소취하 신청서를 재판부에 제출했다.\",\n",
       " '그러나 지난해 12월 4일 도교육청이 소취하에 동의하지 않는다는 의견을 내면서 재판이 재개됐다.',\n",
       " '도교육청은 2017년 사립유치원 종합감사를 통해 은성유치원 회계 비리를 적발하고, 원장 정직을 유치원측에 요구했다.',\n",
       " '은성유치원은 이에 반발해 도교육청에 대해 행정소송을 제기했다.',\n",
       " '도교육청이 소 취하를 거부한 이유는 소송을 진행해 사립유치원 감사 업무 기준이 되는 판례를 만들겠다는 것이다.',\n",
       " '교육청 관계자는 \"판례가 있게 되면 행정 추진 기준으로 삼을 수 있다\"며 \"법원의 최종 판단을 받기 위해 소취하에 부동의했다\"고 전했다.',\n",
       " \"은성유치원은 오는 28일까지 폐원하겠다며 청주시교육지원청에 '학교 폐쇄 인가신청서'를 제출했다.\",\n",
       " '이날은 재개된 소송의 다음 재판이 열리는 변론기일이다.',\n",
       " '재판 중 폐원이 완료되면 소송을 유지할 이익이 사라지기 때문에 법원이 선고 때 본안 판단없이 각하 결정할 공산이 크다.',\n",
       " \"배우 인교진과 최대철이 드라마 '동백꽃 필 무렵'에서 특급 카메오로 활약 했다.\",\n",
       " \"인교진과 최대철은 지난 30일 방송된 KBS2 수목극 '동백꽃 필 무렵'(극본 임상춘, 연출 차영훈)에서 강하늘의 두 형으로 등장했다.\",\n",
       " '아버지 제삿날을 맞아 덕순(고두심 분)의 식당에 찾아온 그림이었다.',\n",
       " '그 시간 용식(강하늘 분)은 동백(공효진 분)을 만나려다 정숙(이정은 분)의 \"동백이를 만나면 어머니는? 어중간하게 착하려면 그만 둬\"라는 말에 뭔가 결심한 듯 돌아왔고, 동백과 만남을 허락해달라고 엄마 덕순의 식당 문을 연 순간 형들과 마주쳤다.',\n",
       " '꽃을 든 용식을 본 둘째 형(인교진 분)은 \"누가 있는겨. 형들한테 상의를 해야지\"라고 궁금해했고, 첫째 형(최대철 분)은 \"결혼하기 전에 연애 많이 해봐\"라고 말했다.',\n",
       " '하지만 형들도 아이가 있는 미혼모 동백을 받아들이긴 어려웠고, \"엄마한테 못할 짓\"이라고 꾸짖었다.',\n",
       " '특히 둘째 형인 인교진은 \"너 차라리 방아깨비를 잡으러 다녀\"라고 말했고, 이에 용식은 눈을 부라려 보는 이로 하여금 웃음을 유발했다.',\n",
       " \"앞서 인교진과 최대철은 드라마 '백희가 돌아왔다'에서 만난 제작진과 의리로 출연한 것으로 알려졌다.\"]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:02<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for i, sent in enumerate(tqdm(script_list)):\n",
    "    if i + (ws*2) <= len(script_list):\n",
    "        w_input = script_list[i:i+(ws*2)]\n",
    "        \n",
    "        # embedding\n",
    "        emb = embedder.get_embeddings(w_input).transpose(1, 0).cuda()\n",
    "        score = subtext_model(emb.unsqueeze(0))\n",
    "        score_list.append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.86625862121582,\n",
       " -5.065357685089111,\n",
       " -5.856250762939453,\n",
       " -4.983221530914307,\n",
       " -4.679341793060303,\n",
       " -4.1713433265686035,\n",
       " -4.891319751739502,\n",
       " 8.072851181030273,\n",
       " -3.0970635414123535,\n",
       " -3.884166955947876,\n",
       " -7.703949928283691,\n",
       " -5.633543491363525,\n",
       " -6.8576555252075195]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[충청일보 이정규기자] 폐원을 신청한 청주 은성유치원이 충북도교육감을 상대로 낸 행정소송을 취하하려했지만 도교육청이 이를 거부한 것으로 전해졌다.\n",
      "6일 충북도교육청에 따르면 은성유치원은 지난 2017년 7월 도교육감을 상대로 '징계의결 요구 처분 취소' 청구소송을 낸 후 지난해 12월 27일 소취하 신청서를 재판부에 제출했다.\n",
      "그러나 지난해 12월 4일 도교육청이 소취하에 동의하지 않는다는 의견을 내면서 재판이 재개됐다.\n",
      "-4.87 \n",
      " 도교육청은 2017년 사립유치원 종합감사를 통해 은성유치원 회계 비리를 적발하고, 원장 정직을 유치원측에 요구했다.\n",
      "-5.07 \n",
      " 은성유치원은 이에 반발해 도교육청에 대해 행정소송을 제기했다.\n",
      "-5.86 \n",
      " 도교육청이 소 취하를 거부한 이유는 소송을 진행해 사립유치원 감사 업무 기준이 되는 판례를 만들겠다는 것이다.\n",
      "-4.98 \n",
      " 교육청 관계자는 \"판례가 있게 되면 행정 추진 기준으로 삼을 수 있다\"며 \"법원의 최종 판단을 받기 위해 소취하에 부동의했다\"고 전했다.\n",
      "-4.68 \n",
      " 은성유치원은 오는 28일까지 폐원하겠다며 청주시교육지원청에 '학교 폐쇄 인가신청서'를 제출했다.\n",
      "-4.17 \n",
      " 이날은 재개된 소송의 다음 재판이 열리는 변론기일이다.\n",
      "-4.89 \n",
      " 재판 중 폐원이 완료되면 소송을 유지할 이익이 사라지기 때문에 법원이 선고 때 본안 판단없이 각하 결정할 공산이 크다.\n",
      "8.07 \n",
      " 배우 인교진과 최대철이 드라마 '동백꽃 필 무렵'에서 특급 카메오로 활약 했다.\n",
      "-3.10 \n",
      " 인교진과 최대철은 지난 30일 방송된 KBS2 수목극 '동백꽃 필 무렵'(극본 임상춘, 연출 차영훈)에서 강하늘의 두 형으로 등장했다.\n",
      "-3.88 \n",
      " 아버지 제삿날을 맞아 덕순(고두심 분)의 식당에 찾아온 그림이었다.\n",
      "-7.70 \n",
      " 그 시간 용식(강하늘 분)은 동백(공효진 분)을 만나려다 정숙(이정은 분)의 \"동백이를 만나면 어머니는? 어중간하게 착하려면 그만 둬\"라는 말에 뭔가 결심한 듯 돌아왔고, 동백과 만남을 허락해달라고 엄마 덕순의 식당 문을 연 순간 형들과 마주쳤다.\n",
      "-5.63 \n",
      " 꽃을 든 용식을 본 둘째 형(인교진 분)은 \"누가 있는겨. 형들한테 상의를 해야지\"라고 궁금해했고, 첫째 형(최대철 분)은 \"결혼하기 전에 연애 많이 해봐\"라고 말했다.\n",
      "-6.86 \n",
      " 하지만 형들도 아이가 있는 미혼모 동백을 받아들이긴 어려웠고, \"엄마한테 못할 짓\"이라고 꾸짖었다.\n",
      "특히 둘째 형인 인교진은 \"너 차라리 방아깨비를 잡으러 다녀\"라고 말했고, 이에 용식은 눈을 부라려 보는 이로 하여금 웃음을 유발했다.\n",
      "앞서 인교진과 최대철은 드라마 '백희가 돌아왔다'에서 만난 제작진과 의리로 출연한 것으로 알려졌다.\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(script_list):\n",
    "    if (i >= ws) & (i <= len(script_list) - ws):\n",
    "        j = (i-ws)\n",
    "        print(f\"{score_list[j]:.2f}\", '\\n', sent)\n",
    "    else:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=3\n",
    "tmp_src = mixed_doc_list[100][0].split('\\n')\n",
    "tmp_cands = [tmp_src[i:i+ws*2] for i, _ in enumerate(tmp_src) if i <= len(tmp_src) - ws*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [get_divscore(src_doc=cand, embedder=embedder, divider=subtext_model) for cand in tmp_cands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 유튜브"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import doc_preprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_script_pth = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/youtube_dataset/label/KBS뉴스_7_XpWIWY6pQ_27m_51s.txt'\n",
    "with open(youtube_script_pth, 'rb') as rr:\n",
    "    youtube_df = json.load(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = youtube_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_fin = doc_preprocess(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_list = [sent for sent in script_fin.split('\\n') if len(sent.strip()) >= 20]#[:50]\n",
    "#script_list = [sent for sent in script_fin.split('\\n')][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:44<00:00,  4.03it/s]\n"
     ]
    }
   ],
   "source": [
    "subtext_model.eval()\n",
    "\n",
    "score_list = []\n",
    "for i, sent in enumerate(tqdm(script_list)):\n",
    "    if i + (ws*2) <= len(script_list):\n",
    "        w_input = script_list[i:i+(ws*2)]\n",
    "        \n",
    "        # embedding\n",
    "        emb = embedder.get_embeddings(w_input).transpose(1, 0).cuda()\n",
    "        score = subtext_model(emb.unsqueeze(0))\n",
    "        score_list.append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여러분 안녕하십니까 코로나19 통합 뉴스룸 시작합니다\n",
      "기후변화 위기 대처 방안을 마련하기 위해 세계 각국 정상들이 화상으로 만났습니다\n",
      "나라별로 온실가스 감축 목표를 추가로 내놓고 공동 대응을 다짐하는 자리였는데요\n",
      "-9.32 \n",
      " 탄소를 가장 많이 배출하고 있는 미국과 중국 간에는 주도권을 둘러싼 신경전도 벌어졌습니다\n",
      "-8.42 \n",
      " 기후변화 대처를 위한 화상회의에 세계 각국 정상급 인사 40명이 참석했습니다\n",
      "-6.38 \n",
      " 회의를 개최한 조 바이든 미국 대통령은 기후변화를 실존적 위기로 규정하고 2030년까지 온실가스 배출량을 2005년을 기준으로 절반 넘게 줄이겠다는 새 목표를 제시했습니다\n",
      "-7.70 \n",
      " 이는 기존 계획보다 2배 가까이 강화된 목표로 바이든 대통령은 미국의 선제적 감축에 호응하는 세계 각국의 공동 노력을 호소했습니다\n",
      "-5.85 \n",
      " 실제 유럽연합의 경우 감축 목표를 기존보다 15%포인트 가량 상향 조정했고 캐나다와 일본도 강화된 목표치를 내놨습니다\n",
      "-6.67 \n",
      " 반면 중국과 인도 러시아 등 온실가스 배출량이 많은 나라들은 추가 감축 목표를 제시하지 않았습니다\n",
      "-4.62 \n",
      " 시진핑 중국 국가주석은 대신 개발도상국과 선진국 간 서로 다른 이해관계의 조정 등을 위해선 미국이 아닌 유엔을 비롯한 국제기구가 논의 중심이 돼야 한다고 강조했습니다\n",
      "========(4.39)======== \n",
      " 중상 치다의 동 방사능이 몇 곳이에요\n",
      "========(3.43)======== \n",
      " 그럼 너무 이쁘지 현재 환인점이라는 놈이 세계 각국은 이번 정상회의 논의 결과를 바탕으로 오는 11월 영국에서 개최될 유엔 기후변화협약 총회에서 보다 구체화된 형태의 공동 목표를 내놓을 것으로 예상됩니다\n",
      "-3.97 \n",
      " 문재인 대통령은 어젯밤 기후정상회의에 참석했습니다\n",
      "-7.55 \n",
      " 문 대통령은 온실가스 감축 목표 상향과 함께 신규 해외 석탄화력발전소에 대한 공적금융지원을 중단하겠다는 두 가지 핵심 약속을 발표했습니다\n",
      "-7.11 \n",
      " 지난해 10월 2050 탄수 중립 목표를 선언했던 문 대통령은 이를 실현하기 위한 계획을 밝혔습니다\n",
      "-6.73 \n",
      " 먼저 파리 협정 이행 첫 해이자 2050 탄소 중립 이행 원년을 맞아 온실가스 감축을 위한 노력을 강조했습니다\n",
      "-8.25 \n",
      " 한국은 2030 국가 온실가스 감독목표 엔지시를 추가 상향하여 올해 안에 이에 대해 제출할 것입니다\n",
      "-7.37 \n",
      " 전 세계적인 탈석탄 노력에 동참하겠다는 의지도 확실히 했습니다\n",
      "-10.26 \n",
      " 이를 위해 신규 해외 석탄화력발전소에 대한 공적 금융지원을 전면 중단하겠다고 말했습니다\n",
      "-7.49 \n",
      " 탄소 배출 세계 6위라는 오명에서 벗어나기 위한 우리나라의 노력도 설명했습니다\n",
      "-9.35 \n",
      " 우리 정부는 출범 후 석탄화력발전을 과감히 감축했으며 대신 태양광과 풍력 등 재생에너지 발전을 빠르게 늘리고 있습니다\n",
      "-8.44 \n",
      " 다만 국내적으론 관련 산업과 일자리 등에 미칠 부정적 영향에 대한 대책이 필요하다며 국내외 재생에너지 설비 등에 투자하는 녹색 금융 확대를 적극 추진하겠다고 말했습니다\n",
      "-8.71 \n",
      " 이어 각국 정상들을 향해선 석탄화력발전 의존도가 큰 개발 도상국 등에 대한 지원 방안 마련도 촉구했습니다\n",
      "-6.54 \n",
      " 문 대통령은 특히 기후 대응을 위한 전 세계적인 노력의 연장선상에서 다음 달 우리나라에서 열리는 p4g 정상회의에 대한 각국의 관심을 당부했습니다\n",
      "-6.65 \n",
      " 한미 정상은 지난 2월 첫 정상 통화에 이어 비록 화상이지만 어제 처음으로 얼굴을 마주했습니다\n",
      "-6.08 \n",
      " 청와대는 양국 간 기후변화 대응 협력을 강화해 다각적인 차원에서 한미동맹 확대를 기대한다고 밝혔습니다\n",
      "-3.84 \n",
      " 정부가 검토 차원이라고 일단 선을 그었지만 백신 수급을 다각하기 위한 이른바 플랜B 중의 하나로 러시아의 스포트니크 V백신이 관심을 끌고 있습니다\n",
      "-2.74 \n",
      " 어떤 객실이고 접촉에 문제는 없는 건지 신미래 의학전문기자가 짚어봤습니다\n",
      "-5.30 \n",
      " 지난해 8월 러시아가 세계 최초로 사용승인한 스프트니크 v 백신 아스트라제네카 백신과 같은 원리로 개발됐습니다\n",
      "-4.94 \n",
      " 코로나바이러스 유전자를 아데노바이러스 전달 제한을 실어 인체에 주사하는 방식입니다\n",
      "-7.37 \n",
      " 화이자 백신처럼 3주 간격으로 두 차례 접종하는데 서로 다른 종류의 인간 아데노바이러스를 사용하게 됩니다\n",
      "-6.48 \n",
      " 바이러스가 우리 몸의 색으로 들어가서 단백질을 발현해야만 작용을 하는데 그렇게 되는 바이러스 양이 훨씬 줄어들어버리는 거예요\n",
      "-5.62 \n",
      " 서로 다른 걸 쓰는 게 중요한 것 당초 러시아에서 임상 일상과 이상만으로 백신을 승인해 효능에 대한 논란이 있었지만 지난 2월 세계적 의학 학술지 낸시세 임상 3상 결과 예방 효과가 91.6%에 달한다는 내용이 실려 주목을 받았습니다\n",
      "-6.71 \n",
      " 전 세계 60여개국이 사용을 허가한 가운데 유럽의약품청은 이달 초부터 심사에 들어간 상태입니다\n",
      "-6.98 \n",
      " 러시아에서는 지난달까지 700만 명 이상 접종을 마쳤지만 부작용 사례가 투명하게 집계되거나 공개되지 않은 만큼 섣부른 도입은 어렵다는 겁니다\n",
      "-2.73 \n",
      " 구자경 보고가 제대로 보고가 되고 빅데이터 측면에서 제대로 관리는 되고 있는지에 대한 우려가 아직 많이 남아 있기는 한 거죠\n",
      "-3.22 \n",
      " 전문가들은 스프트니크 v 백신이 희귀열전 부작용이 발생한 아스트라제네카 백신 얀센 백신과 같은 방식인 만큼 면밀한 안전성 검토가 필요하다고 지적합니다\n",
      "========(2.20)======== \n",
      " 유럽연합 eu가 물량을 제때 공급하지 못하고 있는 아스트라 제네카 백신을 추가 구매하지 않겠다고 밝혔습니다\n",
      "-6.75 \n",
      " 한편 독일은 늦어도 6월부터는 우선순위 없이 누구나 코로나19 백신 접종을 받을 수 있게 할 계획입니다\n",
      "-5.34 \n",
      " 유럽연합 집행위원회는 현지시간 22일 아스트라 제네카 백신의 추가 구매가 없을 것이라고 밝혔습니다\n",
      "-6.71 \n",
      " 원래 공급 계약에 포함된 1억 회분의 추가 구매 옵션을 행사하지 않는다는 겁니다\n",
      "-5.65 \n",
      " 이유는 아스트라 제네카와 상반기 중 3억 회 분 그리고 이렇게 추가 주문 옵션 계약을 맺었습니다\n",
      "-6.39 \n",
      " 하지만 아스트라제네카는 생산 차질을 이유로 1분기 계약 물량 1억 회분 중 3천만 회분만 공급했습니다\n",
      "-8.50 \n",
      " 상반기 중 전체 공급량도 전체 계약 물량의 3분의 1인 1억 회 분에 그칠 것으로 예상됩니다\n",
      "-7.43 \n",
      " 이후 집행위원회는 공급 기한을 어긴 아스트라제네카를 상대로 소송을 제기하겠다는 뜻을 밝혔습니다\n",
      "-2.99 \n",
      " 한편 백신 접종 속도가 더딘 독일은 늦어도 6월부터는 우선순위 없이 희망자 누구나 접종을 받을 수 있게 할 계획입니다\n",
      "-8.57 \n",
      " 현재까지는 접종 우선순위인 고령자와 의료진 등에 대한 접종이 진행되고 있습니다\n",
      "-5.61 \n",
      " 독일 연방정부는 5월부터 백신 접종 우선순위를 두지 않을 정도로 백신 공급이 충분해질 것으로 예상하고 있습니다\n",
      "-3.12 \n",
      " 한편 베를린시와 바이에른 등 일부 연방주들은 현지시간 22일부터 아스트라자나카 백신에 대해 우선순위를 철회하고 원하는 모든 성인의 접종을 허용한다고 밝혔습니다\n",
      "========(1.02)======== \n",
      " 프랑스 정부가 스트레젤 핵화 백신 10만 회분을 코엑스에 기부하기로 했습니다\n",
      "-6.73 \n",
      " 전 세계 첫 사례라고 자랑했지만 프랑스 내에선 해당 백신의 접종 기피 현상으로 애를 먹고 있는데요\n",
      "-6.14 \n",
      " 접종 거부에 백신이 폐기되는 일도 있었습니다\n",
      "-5.76 \n",
      " 프랑스 민방위대 대원들이 길거리 시장에서 백신 접종 홍보를 하고 있습니다\n",
      "-8.46 \n",
      " 하지만 여러 시민이 아스트라지네카 백신에 대해 거부감을 보이고 있습니다\n",
      "-2.42 \n",
      " 고기 아령 서비스센터 소매 기간 인식과 감사합니다\n",
      "-2.30 \n",
      " 그리고 만 5천 원 내고 뭐 어디 파이자 의사들은 접종 기피 현상으로 일부 아스트라제네카 백신이 폐기되는 일도 있다고 말했습니다\n",
      "========(2.53)======== \n",
      " 프랑스 르몽드지는 지금까지 제공된 아스트라지네카 백신의 75%만 사용됐다고 보도했습니다\n",
      "========(2.60)======== \n",
      " 이런 가운데 프랑스 정부가 아스트라제네카 백신 10만의 분을 코덱스 프로젝트에 기부하기로 했습니다\n",
      "-8.16 \n",
      " 자국이 확보한 백신을 아프리카 등 개발도상국에 기부하는 첫 사례라고 밝혔습니다\n",
      "-7.93 \n",
      " 로이터 통신은 지금까지 코엑스에 현금 지원은 있었지만 백신 기부는 한 건도 없었다고 전했습니다\n",
      "-3.81 \n",
      " 프랑스는 6월 중순까지 모두 50만 해군을 코엑스에 기부할 계획이라며 아스트라지네카 백신의 효과성을 강조했습니다\n",
      "========(0.47)======== \n",
      " 매일 34만 명의 코로나19 신규 확진자가 발생하고 있는 프랑스 프랑스 정부는 그러나 코로나 확산이 정점을 지나고 있다며 5월 3일부터 전국적인 3차 봉쇄령을 단계적으로 완화하겠다고 밝혔습니다\n",
      "========(1.51)======== \n",
      " 코로나19 이후 급격히 늘고 있는 아시아계 증오 범죄와 관련해 미 상원에서 아시아계 증오 범죄 방지 법안이 압도적 지지 속에 통과됐습니다\n",
      "-7.54 \n",
      " 하원은 다음 달 이 법안을 통과시킬 계획인 것으로 전해졌습니다\n",
      "-4.34 \n",
      " 코로나19 이후 급격히 늘어난 아시아계 증오 범죄에 강력히 대처하는 내용의 이른바 아시아계 증오 범죄 방지 법안이 미국 상원에서 압도적인 찬성으로 가결됐습니다\n",
      "-8.22 \n",
      " 미 상원 100명 가운데 94명이 찬성 1명이 반대해 초당적인 지지를 받았습니다\n",
      "-6.96 \n",
      " 안 냈으면 정식 명칭은 코로나19 증오 범죄 법안으로 특정 인종과 코로나바이러스를 연결해 일어나는 모든 폭력 행위를 증오 범죄로 규정해 이를 엄단하도록 하는 내용을 담고 있습니다\n",
      "-5.54 \n",
      " 법무부가 적극적으로 증오 범죄를 검토하고 주 정부는 증오 범죄 신고 핫라인을 개설해 특정 인종에 대한 공격을 별도로 대응하는 체계를 만들도록 했습니다\n",
      "-6.20 \n",
      " 아시아계가 코로나19 표적이 된 만큼 사실상 아시아계 증오 범죄 방지가 목적입니다\n",
      "-7.50 \n",
      " 미국에서는 지난해 코로나19의 세계적 유행 이후 트럼프 전 대통령이 코로나와 중국을 연결지으며 아시아계를 겨냥한 범죄가 급증했습니다\n",
      "-7.19 \n",
      " 특히 지난달 미 애틀랜타에서 연쇄 총격으로 한인 여성 4명 등 아시아계 여성 6명이 사망한 사건이 분노를 지켜 미 전역에서 아시아인에 대한 증오를 멈추라는 시위가 이어지기도 했습니다\n",
      "-6.92 \n",
      " 다음 달 미 하원에서 법안이 통과되고 바이든 대통령이 서명하면 미국에서 처음으로 아시아계 증오범죄 대응이 법제화됩니다\n",
      "-0.08 \n",
      " 지난달 대전의 한 어린이집 원장이 생후 21개월 된 여아를 재운다며 몸으로 아이를 눌러 숨지게 한 사건이 있었는데요\n",
      "-4.39 \n",
      " 당시 cctv가 공개됐는데 학대 정황이 드러났습니다\n",
      "-5.62 \n",
      " 부검 결과 질식사 소견이 나온 것으로 알려진 가운데 경찰은 구속영장을 다시 신청할 방침입니다\n",
      "-6.22 \n",
      " 어린이집 원장이 낮잠을 자는 아이들 사이에 21개월 된 여아를 내려놓고 이불로 싸맵니다\n",
      "-6.28 \n",
      " 그리고는 옆에 눕더니 엎드린 아이 위로 자신의 팔과 다리를 올린 채 몸을 기울여 누르기 시작합니다\n",
      "-6.65 \n",
      " 아이고 이런 자세는 10분 넘게 계속됐습니다\n",
      "-6.91 \n",
      " 몸이 눌린 아이는 조금 뒤 움직임을 멈춥니다\n",
      "-4.87 \n",
      " 1시간쯤 뒤 아이가 숨을 쉬지 않는 걸 확인한 원장은 심폐소생술을 하지만 아이는 끝내 숨졌습니다\n",
      "-4.97 \n",
      " 앞서 경찰은 이 cctv를 근거로 원장에 대해 아동학대 치사 혐의로 구속영장을 신청했지만 검찰은 보완 수사가 필요하다며 반려했습니다\n",
      "-6.76 \n",
      " 경찰은 국과수의 부검 결과 아이가 질식사했다는 소견을 통보받은 것으로 알려졌습니다\n",
      "-5.48 \n",
      " 경찰은 원장에 대해 구속영장을 다시 신청할 예정입니다\n",
      "-4.08 \n",
      " 그걸 하고 받았고 하고 받은 결과를 토대로다가 여러 가지 또한 보완수사를 진행해서 유가족들은 원장의 행동에 미필적 고의가 있었다며 살인 혐의를 적용해야 한다고 주장합니다\n",
      "-5.11 \n",
      " 얼굴을 바닥으로 눕히고 거기다 지금 이불을 그리고 자기의 체중을 다 실었다는 것은 경험직상 이 위험을 인식할 수 있기 때문에 미필적 고의가 있다고 유가족 측은 원장에 대해 아동학대 살해 혐의를 적용해달라는 고소장을 제출했습니다\n",
      "========(1.24)======== \n",
      " 이번엔 kb증권 연결해서 오늘의 주식시장 알아보겠습니다\n",
      "========(5.84)======== \n",
      " 부진 여파로 유가증권시장도 저조한 모습을 나타내고 있습니다\n",
      "-3.25 \n",
      " 코스닥은 뚜렷한 방향을 잡지 못한 채 보합권에서 횡보하고 있습니다\n",
      "-7.53 \n",
      " 이 시각 현재 코스피는 11.18포인트 하락한 3166.34에 코스닥은 0.71포인트 내린 1025에 거래되고 있습니다\n",
      "-5.62 \n",
      " 조 바이든 미국 대통령이 고소득자에 대한 양도소득세 인상을 검토하고 있다는 소식에 간밤 미국 증시는 일제히 1% 가까이 하락했습니다\n",
      "-8.52 \n",
      " 코스피 역시 외국인과 기관의 동반 팔자세가 유입되며 저조한 흐름을 나타내고 있습니다\n",
      "-3.54 \n",
      " sk하이닉스가 하루 만에 반락하며 13만 원선이 위협받고 있고 비트코인이 10% 가까이 급락하고 당국에서도 암호화폐 투기 열풍에 대한 압박 수위를 높이자 암호화폐 관련주가 동반 내림세입니다\n",
      "-7.10 \n",
      " 반면 올해 1분기 사상 최대 순이익을 기록한 kb금융은 강세를 보이고 있습니다\n",
      "-3.71 \n",
      " 이 시각 현재 달러화에 대한 원화 환율은 1119원 30전에 거래되고 있습니다\n",
      "========(5.43)======== \n",
      " 강센 놈 일본에서도 코로나19 백신 접종을 시작했으나 각 지자체별로 제대로 된 수요 파악 등이 되지 않아 접종 계획에 차질을 빚고 있습니다\n",
      "-2.74 \n",
      " 각 구별로 백신 수급량이 천차만별이어서 정부의 접종 계획에 영향을 주고 있습니다\n",
      "-1.95 \n",
      " 예를 들어 도쿄 도심하고는 백신 공급 자체가 많지 않을 거라고 생각해 2주 치분인 세상자 2925회 분만 요청했지만 더 많은 사람들이 백신 접종을 희망해 백신이 절대적으로 모자라는 상황입니다\n",
      "-7.63 \n",
      " 스트레스로 그랬듯이 나은 반대로 도쿄 가치 시가구는 필요 양보다 더 많이 요청해 백신이 남아돌 것으로 보입니다\n",
      "-6.27 \n",
      " 이런 혼란은 일본 정부가 백신 배포와 관련한 통일된 기준을 제시하지 못했기 때문으로 분석됩니다\n",
      "-7.55 \n",
      " 그 여파로 접종 예약 현장에서도 혼란이 일고 있습니다\n",
      "-5.97 \n",
      " 미야자키현 미야 코너 조 씨는 선착순으로 백신 접종 예약을 받았더니 한꺼번에 신청이 몰려 전화와 인터넷 모두 연결되지 않았습니다\n",
      "-3.69 \n",
      " 전문가들은 백신으로 인한 집단 면역 효과를 얻기 위해서는 짧은 시간에 최대한 많은 접종을 해야 하는 만큼 무엇보다 치밀한 접종 계획이 필요하다고 말합니다\n",
      "========(1.61)======== \n",
      " 용체 검을 최근 미국에서 총기난사 사건이 유행병처럼 번지고 있어 우려가 큽니다\n",
      "-7.21 \n",
      " 지난주 미국 인디애나폴리스에서 19살 청년이 총기로 8명을 사살하고 자살했습니다\n",
      "-5.56 \n",
      " 미국에선 3명 이상이 죽거나 다칠 경우 대규모 총기 난사로 규정하는데요\n",
      "-8.07 \n",
      " 지난달 이후 미국 전역에서 이런 총기 난사 사건이 50건이나 발생했습니다\n",
      "-6.69 \n",
      " 매년 3만 8천 명이 숨지는 총기 범죄는 미국에서 조기 사망의 첫 번째 원인입니다\n",
      "-4.09 \n",
      " 게리는 귀여워 그냥 이미 왜 제 앞에 내가 하고 있는 전문가들과 관리들은 미국인들이 이제는 대규모 총기 범죄를 당연한 일로 받아들일 수 있다는 점을 우려합니다\n",
      "-5.51 \n",
      " 아니 문제는 형제규제를 강화하는 입법이 쉽지 않다는 것입니다\n",
      "-5.56 \n",
      " 바이든 대통령은 더 엄격한 총기규제법으로 총기 사고를 뿌리뽑길 원하지만 공화당뿐 아니라 일부 민주당 의원들의 반대로 의회 통과가 쉽지 않습니다\n",
      "========(2.88)======== \n",
      " 중국 어린이와 청소년들 대부분이 학업부담과 지나친 스마트 기기 사용 등으로 잠을 충분히 자지 못하는 것으로 나타났습니다\n",
      "-6.87 \n",
      " 매년 중국 정부가 조사하는 중국 국민 심리 건강 발전 보고에 따르면 중국 어린이와 청소년들의 수면 부족 현상이 갈수록 악화하고 있습니다\n",
      "-4.22 \n",
      " 초등학생의 95.5% 중학생 90.8%와 고등학생 84.1%가 기준치에 못 미치는 수면 시간을 기록했습니다\n",
      "-7.70 \n",
      " 이유는 무엇일까 과중한 학업 부담이 첫 번째 원인입니다\n",
      "-6.81 \n",
      " 휴대전화와 태블릿pc 등 스마트 전자기기를 과도하게 사용하는 것도 문제점으로 지적됐습니다\n",
      "-2.96 \n",
      " 전문가들은 잦은 수면 부족은 심리적 불안과 처절을 유발하고 면역력을 저하시켜 갖가지 질병에 쉽게 걸리게 하는 만큼 성장기 어린이와 청소년들에게 특히 나쁜 영향을 미친다고 지적합니다\n",
      "-3.54 \n",
      " 스웨덴 북부 노르란드 지역의 라플란트 지방은 서쪽으로 노르웨이 북쪽으로 핀란드를 접하고 있습니다\n",
      "-5.29 \n",
      " 이 지역이 3위 원주민들에게 슬로건 크리스마스를 상징하는 의미 이상입니다\n",
      "-6.20 \n",
      " 슬로건 3위 원주민들에게 수세기 동안 교통수단과 고기를 제공하는 등 삶의 원동력이었습니다\n",
      "-5.64 \n",
      " 지금은 순록 관광을 생업으로 하는 3위 쪽의 10%만이 순록과 함께 생활하고 있습니다\n",
      "-2.59 \n",
      " 이곳에서 인기인 순록 썰매 관광은 관광객들을 신비로운 동심으로 돌아가게 합니다\n",
      "========(4.44)======== \n",
      " 관광객들에게 술로 고기는 다른 지역에서 쉽게 맛볼 수 없는 별미인 동시에 쉽지 않은 도전입니다\n",
      "-3.24 \n",
      " 스웨덴 내 2만 명의 사미족들은 현대화와 함께 수록에 대한 의존도가 낮아지고 있지만 여전히 슬로건 사미족의 역사적인 상징이라고 말합니다\n",
      "========(6.05)======== \n",
      " 베리치 사태로 처리에 속도가 붙고 있는 이해충돌방지법이 어제 소관 상임위를 통과했습니다\n",
      "-5.96 \n",
      " 그런데 살펴보니 공직자와 국회의원들에 대한 외부 감시가 쉽지 않은 사각지대도 남아 있었습니다\n",
      "-6.14 \n",
      " 공직자 190만 명에게 직접 적용될 이해충돌방지법이 상임위 문턱을 넘었습니다\n",
      "-7.31 \n",
      " 본인은 물론 가족까지 미공개 정보로 사적 이익을 못 얻게 하자는 게 법의 취지입니다\n",
      "-6.68 \n",
      " 공룡사회 구축을 위해 여야가 의지를 한곳으로 모았다는 점에서 큰 성과로 생각합니다\n",
      "-8.59 \n",
      " 그런데 법안의 실효성에 영향을 줄 조항이 논의 과정에서 빠진 것으로 파악됐습니다\n",
      "-8.09 \n",
      " 사적 이해관계를 매년 등록하고 특히 고위공직자의 경우엔 공개까지 하자고 한 내용이 사라진 겁니다\n",
      "-8.40 \n",
      " 이 정보가 있어야 이해충돌 우려를 피해갈 수 있는데 본인의 신고에만 맡겨뒀습니다\n",
      "-9.39 \n",
      " 등록해도 현실적으로 소속 기관에서 일일이 다 파악할 수 있겠냐는 이유에서였습니다\n",
      "-2.06 \n",
      " 고위공직자는 과거 민간에서의 경력만 소속 기관장이 공개할 수 있다고 정리됐습니다\n",
      "-6.39 \n",
      " 민간업무 활동 내역이라고 하는 부분이 공개가 의무 조항이 아니라 공개할 수 있다\n",
      "-6.45 \n",
      " 누구나 언제든지 이해충도 정보에 대해서 접근이 가능하고 알 수 있습니다\n",
      "-9.03 \n",
      " 있어야 스스로도 조심하지 못한 이해충돌의 상황에 대해서 방지를 할 수 있다\n",
      "========(1.31)======== \n",
      " 좀 아쉬운 점이 있는 자신들의 이해관계 정보는 비공개하기로 했던 국회의원들은 의원 본인의 정보는 공개할 수 있다로 바꿨습니다\n",
      "-0.69 \n",
      " 셀프 특혜냐는 비판에 공개할 수 있게는 했다지만 공개를 의무화한 건 아닙니다\n",
      "========(7.62)======== \n",
      " 일본 정부의 방사능 오염수 방류 결정에 대해 부산환경운동연합이 운영사인 도쿄전력을 상대로 소송을 제기했습니다\n",
      "-5.17 \n",
      " 오염수 방류를 막아달라는 첫 법적 조치입니다\n",
      "-2.93 \n",
      " 부산 환경운동연합이 원전 오염수 방류금지 청구 소송을 부산지법에 제기했습니다\n",
      "-6.31 \n",
      " 소송 대상은 일본 후쿠시마 제1원전 운영사 도쿄전력 홀딩스 주식회사입니다\n",
      "-5.65 \n",
      " 일본 정부가 오염수 방류를 결정한 뒤 국내에서 제기된 첫 소송입니다\n",
      "-4.75 \n",
      " 부산환경운동연합은 이웃 거주자 생활에 고통을 주지 않도록 해야 한다는 현행법 규정을 소송의 근거로 제시했습니다\n",
      "-6.64 \n",
      " 1급 발암물질인 세슘과 스트론 흉 등은 아무리 희석해도 인체에 유해한 만큼 일본의 오염수 방류는 우리 국민의 건강에 악영향을 미칠 수 있다는 겁니다\n",
      "-6.55 \n",
      " 방류량을 희석시켜서 서서히 20년 30년에 걸쳐서 방류하겠다고 하더라도 해양 생물들이 먹게 되었을 때는 먹이사슬을 통해서 더욱더 농축이 되어서 우리에게 들어올 것이라고 소송 대리인 측은 일본의 해양 방류 시점인 2023년 전까지 1심 판결 결과가 나올 것으로 예상했습니다\n",
      "-4.16 \n",
      " 우리나라 법원에서 우리의 주권에 의해서 판단을 받는 게 굉장히 의미가 있다고 봅니다\n",
      "-1.80 \n",
      " 신속하게 제기해서 해양 방류를 금지하는 판결을 바다도 좋아합니다\n",
      "-6.14 \n",
      " 만약 소송 과정에서 방류가 진행될 경우 금전적 책임도 묻겠다는 전략입니다\n",
      "========(0.40)======== \n",
      " 오염수 방류 결정에 대한 사회 각계의 반발이 거센 가운데 이번 소송이 당뇨 금지에 대한 법적 근거를 마련할 수 있을지 관심이 쏠리고 있습니다\n",
      "========(3.00)======== \n",
      " 구미한 빈집에서 3살 여자아이가 숨진 채 발견된 사건과 관련해 아이의 친모 성모씨에 대한 첫 재판이 열렸습니다\n",
      "-5.31 \n",
      " 석 씨는 출산 사실을 완강히 부인했지만 시신을 유기하려 했다는 혐의는 인정했습니다\n",
      "-5.46 \n",
      " 홍승현 기자 경북 구미에서 방치된 채 숨진 3살 여자아이의 친모 성모 씨가 고개를 숙인 채 법원으로 들어섭니다\n",
      "-6.20 \n",
      " 석 씨는 미성년자 약취와 사체 은닉 미수 혐의를 받고 있습니다\n",
      "-6.67 \n",
      " 검찰은 첫 재판에서 석 씨가 구미의 한 산부인과에서 친딸 22살 김 모 씨가 낳은 아이와 자신이 출산한 아이를 바꿔치기해 미성년자를 약취했다고 밝혔습니다\n",
      "-7.10 \n",
      " 다만 산부인과에서 어떻게 바꿔치기했는지 이후 어떻게 데리고 나왔는지를 명확히 입증하지 못했습니다\n",
      "-6.67 \n",
      " 이에 대해 석 씨의 변호인은 바꿔치기하려면 아이가 2명 있어야 하는데 석 씨는 출산 사실이 없어 혐의의 전제가 성립하지 않는다고 주장했습니다\n",
      "-6.30 \n",
      " 다만 숨진 아이의 시신을 유기하려 했다는 혐의는 인정했습니다\n",
      "-7.79 \n",
      " 거기에는 공수사실 제1항하고 관련되거나 그걸 추단할 수 있을 만한 사실이 공수 사실이 없습니다\n",
      "-3.97 \n",
      " 법정 밖에선 석 씨에게 강력한 처벌을 해달라는 시위가 벌어졌습니다\n",
      "-6.54 \n",
      " 생명을 잔인하게 방치를 해서 죽인 거기 때문에 그만큼자기가 저지른 그 죄라면 당연히 그만큼의 죗값은 받아야 한다고 다음 재판은 다음 달 11일 열립니다\n",
      "========(1.03)======== \n",
      " 군이 영화 사건에 대한 본격적인 법원의 시간이 시작된 가운데 숨진 아이와 아이 바꿔치기 의혹 등을 둘러싼 진실이 규명될 수 있을지 주목됩니다\n",
      "-0.64 \n",
      " 이렇게 구름이 이불처럼 덮여 있는데다 따뜻한 남풍이 계속해서 불어들어 오늘 아침 기온이 크게 떨어지지 못했습니다\n",
      "-5.40 \n",
      " 아침에 목포가 18.8도 북창원이 16.7도 등 남부 일부 지방의 4월 최저기온이 관측 이래 가장 높았습니다\n",
      "-4.65 \n",
      " 오늘은 낮 동안 수도권과 강원 산지 충청과 전북 동부 경상도 서부 내륙 지역에 1mm 안팎의 비가 오는 곳이 있겠습니다\n",
      "-7.57 \n",
      " 하지만 비가 내리더라도 비의 양이 워낙 적어서 건조특보는 계속 유지되겠습니다\n",
      "-6.79 \n",
      " 특히 건조주의보가 발효 중인 남해안 일부 지역과 제주도는 바람도 강하게 부는 만큼 작은 불씨가 큰 불로 번지지 않게 주의하셔야겠습니다\n",
      "-6.81 \n",
      " 이번 비 소식과 함께 때 이른 더위의 기세는 한풀 꺾이겠습니다\n",
      "-2.34 \n",
      " 오늘은 오전까지 수도권 지역의 미세먼지 농도가 일시적으로 높겠습니다\n",
      "-7.67 \n",
      " 낮 최고기온은 서울이 23도 등 어제보다 많게는 10도 정도는 낮겠습니다\n",
      "-6.61 \n",
      " 바다의 물결은 먼바다를 중심으로 3.5~4m로 일겠습니다\n",
      "-5.69 \n",
      " 주말인 내일은 대체로 맑겠지만 늦은 오후에 전남 내륙과 경남 내륙 지역에 비가 오는 곳이 있겠고요 일요일인 모레는 강원 영동과 경북 동해안 지방에 산발적으로 비가 내리겠습니다\n",
      "========(2.98)======== \n",
      " 방금 들어온 코로나19 소식 알아보겠습니다\n",
      "========(5.71)======== \n",
      " 코로나19 국내 신규 확진자가 800명에 가까워졌습니다\n",
      "-3.69 \n",
      " 중앙방역대책본부는 오늘 0시 기준 코로나19 신규 확진자가 797명이라고 밝혔습니다\n",
      "-6.87 \n",
      " 지역별 국내 발생 확진자는 서울 198명 경기 290명 등입니다\n",
      "-5.95 \n",
      " 사망자는 3명이 늘어 누적 사망자는 1천811명입니다\n",
      "백신 접종은 지금까지 211만여 명이 마쳤습니다\n",
      "코로나19 통합 뉴스룸은 11시에 이어집니다\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(script_list):\n",
    "    if (i >= ws) & (i <= len(script_list) - ws):\n",
    "        j = (i-ws)\n",
    "        if score_list[j] > 0:\n",
    "            print(f\"========({score_list[j]:.2f})========\", '\\n', sent)\n",
    "        else:\n",
    "            print(f\"{score_list[j]:.2f}\", '\\n', sent)\n",
    "    else:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [0, 1, 1, 5, 0, 0.5, 8],\n",
    "    [-1, -1, 0, 0.4, 1, 2, 3],\n",
    "    [-1, -1, 0, -2, 1, -5, -5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.mean(np.where(A >= 0.5, 1, 0), axis=0) >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
