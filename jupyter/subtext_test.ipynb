{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format=\"%(asctime)s [%(levelname)s] %(message)s\", \n",
    "                    level=logging.INFO,\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(os.path.join(\"./subtext_test_result.log\")),\n",
    "                        logging.StreamHandler()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call model (BertSum/SubtextDivider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) BertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path 추가\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/bertsum')\n",
    "sys.path.append('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/subtext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:47,033 [INFO] PyTorch version 1.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from models.data_loader import TextLoader, load_dataset\n",
    "from src.backbone import ExtTransformerEncoder, ExtSummarizer, WindowEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"visible_gpus\" : -1,\n",
    "    \"temp_dir\" : './tmp/',\n",
    "    \"test_from\": None,\n",
    "    \"max_pos\" : 512,\n",
    "    \"large\" : False,\n",
    "    \"finetune_bert\": True,\n",
    "    \"encoder\": \"bert\",\n",
    "    \"share_emb\": False,\n",
    "    \"dec_layers\": 6,\n",
    "    \"dec_dropout\": 0.2,\n",
    "    \"dec_hidden_size\": 768,\n",
    "    \"dec_heads\": 8,\n",
    "    \"dec_ff_size\": 2048,\n",
    "    \"enc_hidden_size\": 512,\n",
    "    \"enc_ff_size\": 512,\n",
    "    \"enc_dropout\": 0.2,\n",
    "    \"enc_layers\": 6,\n",
    "    \n",
    "    \"ext_dropout\": 0.2,\n",
    "    \"ext_layers\": 2,\n",
    "    \"ext_hidden_size\": 768,\n",
    "    \"ext_heads\": 8,\n",
    "    \"ext_ff_size\": 2048,\n",
    "    \n",
    "    \"accum_count\": 1,\n",
    "    \"save_checkpoint_steps\": 5,\n",
    "    \n",
    "    \"generator_shard_size\": 32,\n",
    "    \"alpha\": 0.6,\n",
    "    \"beam_size\": 5,\n",
    "    \"min_length\": 15,\n",
    "    \"max_length\": 150,\n",
    "    \"max_tgt_len\": 140,  \n",
    "    \"block_trigram\": True,\n",
    "    \n",
    "    \"model_path\": \"./tmp_model/\",\n",
    "    \"result_path\": \"./tmp_result/src\",\n",
    "    \"recall_eval\": False,\n",
    "    \"report_every\": 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:58,074 [INFO] loading configuration file ./tmp/kobert_from_pretrained/config.json\n",
      "2021-05-07 01:07:58,077 [INFO] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 8002\n",
      "}\n",
      "\n",
      "2021-05-07 01:07:58,079 [INFO] loading weights file ./tmp/kobert_from_pretrained/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-07 01:07:59,349 [INFO] All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "2021-05-07 01:07:59,350 [INFO] All the weights of BertModel were initialized from the model checkpoint at ./tmp/kobert_from_pretrained.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtSummarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(8004, 768)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ext_layer): ExtTransformerEncoder(\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (transformer_inter): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "device = \"cpu\" if args.visible_gpus == -1 else \"cuda\"\n",
    "loader = TextLoader(args, device)\n",
    "\n",
    "# model setting\n",
    "ckpt_path = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/bertsum/checkpoint/model_step_24000.pt'\n",
    "checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "bert_model = ExtSummarizer(args, device, checkpoint)\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = WindowEmbedder(model=bert_model, text_loader=loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) SubtextDivider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubtextClassifier(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv1d(768, 128, kernel_size=(4,), stride=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=16, bias=True)\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.subtext_classifier import SubtextClassifier\n",
    "\n",
    "subtext_model = SubtextClassifier(window_size=3).cuda()\n",
    "\n",
    "model_path = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/src/subtext/ckpt/subtext_model_w3.pt'\n",
    "subtext_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "subtext_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Score Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divscore(src_doc=[], embedder=None, divider=None):\n",
    "    embedding = embedder.get_embeddings(src_doc).transpose(1, 0).unsqueeze(0)\n",
    "    score = divider(embedding).item()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 260697 records from /home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/article_dataset/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "news_df = load_jsonl('/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/article_dataset/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "# (1) 글자 개수가 너무 작은 경우 없애기 (30글자 이상)\n",
    "# (2) 문장이 적은 경우 해당 기사 없애기 (10문장 이상)\n",
    "news_clean = []\n",
    "for news in news_df:\n",
    "    news_article = news['article_original']\n",
    "    if len(news_article) >= 10:\n",
    "        article_clean = [sent for sent in news_article if len(sent) >= 30]\n",
    "        news_clean.append(article_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_mixed_doc(news_dataset=None, max_num=1000):\n",
    "    mixed_doc_set = []\n",
    "    for i in range(max_num):\n",
    "        lh_count = min(random.randint(7, 10), len(news_dataset[i]))\n",
    "        rh_count = min(random.randint(7, 10), len(news_dataset[i+1]))\n",
    "\n",
    "        lh_news = news_dataset[i][:lh_count]\n",
    "        rh_news = news_dataset[i+1][:rh_count]\n",
    "        \n",
    "        gt = lh_count - 1\n",
    "\n",
    "        src_doc = '\\n'.join((lh_news + rh_news))\n",
    "        mixed_doc_set.append((src_doc, gt))\n",
    "        \n",
    "    return mixed_doc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020011135)\n",
    "mixed_doc_list = make_mixed_doc(news_dataset=news_clean, max_num=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "loader = TextLoader(args, device)\n",
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:57:07,751 [INFO] working on 20th doc: Accuracy so far is 73.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 30th article\n",
      "Error occurred at 32th article\n",
      "Error occurred at 33th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:57:52,749 [INFO] working on 40th doc: Accuracy so far is 77.78%\n",
      "2021-05-02 19:58:43,279 [INFO] working on 60th doc: Accuracy so far is 80.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 66th article\n",
      "Error occurred at 67th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 19:59:27,099 [INFO] working on 80th doc: Accuracy so far is 75.68%\n",
      "2021-05-02 20:00:19,010 [INFO] working on 100th doc: Accuracy so far is 79.79%\n",
      "2021-05-02 20:01:05,288 [INFO] working on 120th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:01:53,274 [INFO] working on 140th doc: Accuracy so far is 78.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 156th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:02:39,330 [INFO] working on 160th doc: Accuracy so far is 79.74%\n",
      "2021-05-02 20:03:28,138 [INFO] working on 180th doc: Accuracy so far is 79.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 191th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:04:10,577 [INFO] working on 200th doc: Accuracy so far is 80.21%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 206th article\n",
      "Error occurred at 207th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:04:55,522 [INFO] working on 220th doc: Accuracy so far is 80.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 221th article\n",
      "Error occurred at 222th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:05:41,893 [INFO] working on 240th doc: Accuracy so far is 79.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 248th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:06:30,241 [INFO] working on 260th doc: Accuracy so far is 79.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 265th article\n",
      "Error occurred at 266th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:07:16,536 [INFO] working on 280th doc: Accuracy so far is 78.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 291th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:08:05,110 [INFO] working on 300th doc: Accuracy so far is 76.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 300th article\n",
      "Error occurred at 312th article\n",
      "Error occurred at 315th article\n",
      "Error occurred at 316th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:08:52,520 [INFO] working on 320th doc: Accuracy so far is 77.33%\n",
      "2021-05-02 20:09:38,502 [INFO] working on 340th doc: Accuracy so far is 77.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 338th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:10:25,756 [INFO] working on 360th doc: Accuracy so far is 77.29%\n",
      "2021-05-02 20:11:14,110 [INFO] working on 380th doc: Accuracy so far is 77.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 387th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:12:00,515 [INFO] working on 400th doc: Accuracy so far is 77.25%\n",
      "2021-05-02 20:12:48,850 [INFO] working on 420th doc: Accuracy so far is 77.89%\n",
      "2021-05-02 20:13:37,001 [INFO] working on 440th doc: Accuracy so far is 78.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 446th article\n",
      "Error occurred at 447th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:14:19,661 [INFO] working on 460th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:15:05,472 [INFO] working on 480th doc: Accuracy so far is 79.39%\n",
      "2021-05-02 20:15:58,735 [INFO] working on 500th doc: Accuracy so far is 79.41%\n",
      "2021-05-02 20:16:53,206 [INFO] working on 520th doc: Accuracy so far is 79.84%\n",
      "2021-05-02 20:17:42,199 [INFO] working on 540th doc: Accuracy so far is 79.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 546th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:18:28,825 [INFO] working on 560th doc: Accuracy so far is 79.63%\n",
      "2021-05-02 20:19:19,594 [INFO] working on 580th doc: Accuracy so far is 79.82%\n",
      "2021-05-02 20:20:10,408 [INFO] working on 600th doc: Accuracy so far is 80.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 599th article\n",
      "Error occurred at 600th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:20:55,960 [INFO] working on 620th doc: Accuracy so far is 79.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 631th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:21:42,848 [INFO] working on 640th doc: Accuracy so far is 80.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 641th article\n",
      "Error occurred at 648th article\n",
      "Error occurred at 649th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:22:23,885 [INFO] working on 660th doc: Accuracy so far is 80.60%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 663th article\n",
      "Error occurred at 664th article\n",
      "Error occurred at 667th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:23:05,795 [INFO] working on 680th doc: Accuracy so far is 80.50%\n",
      "2021-05-02 20:23:52,135 [INFO] working on 700th doc: Accuracy so far is 80.33%\n",
      "2021-05-02 20:24:43,570 [INFO] working on 720th doc: Accuracy so far is 80.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 726th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:25:32,328 [INFO] working on 740th doc: Accuracy so far is 80.57%\n",
      "2021-05-02 20:26:20,843 [INFO] working on 760th doc: Accuracy so far is 80.28%\n",
      "2021-05-02 20:27:06,800 [INFO] working on 780th doc: Accuracy so far is 80.54%\n",
      "2021-05-02 20:27:59,666 [INFO] working on 800th doc: Accuracy so far is 80.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 798th article\n",
      "Error occurred at 801th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:28:44,063 [INFO] working on 820th doc: Accuracy so far is 80.46%\n",
      "2021-05-02 20:29:38,363 [INFO] working on 840th doc: Accuracy so far is 80.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 854th article\n",
      "Error occurred at 855th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:30:22,763 [INFO] working on 860th doc: Accuracy so far is 80.27%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 869th article\n",
      "Error occurred at 870th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:31:04,383 [INFO] working on 880th doc: Accuracy so far is 80.33%\n",
      "2021-05-02 20:31:47,949 [INFO] working on 900th doc: Accuracy so far is 79.98%\n",
      "2021-05-02 20:32:33,937 [INFO] working on 920th doc: Accuracy so far is 79.64%\n",
      "2021-05-02 20:33:25,227 [INFO] working on 940th doc: Accuracy so far is 79.76%\n",
      "2021-05-02 20:34:13,123 [INFO] working on 960th doc: Accuracy so far is 79.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 967th article\n",
      "Error occurred at 968th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:34:59,979 [INFO] working on 980th doc: Accuracy so far is 79.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred at 983th article\n",
      "Error occurred at 984th article\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-02 20:35:49,014 [INFO] working on 1000th doc: Accuracy so far is 79.27%\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "acc_cnt = 0\n",
    "ws = 3\n",
    "\n",
    "div_result = []\n",
    "for i, a_set in enumerate(mixed_doc_list):\n",
    "    \n",
    "    if (i+1) % 20 == 0:\n",
    "        logger.info(f\"working on {i+1}th doc: Accuracy so far is {acc_cnt/(acc_cnt+err_cnt)*100:.2f}%\")\n",
    "        \n",
    "    src_doc = a_set[0].split('\\n')\n",
    "    gt = a_set[1]\n",
    "    \n",
    "    cands = [src_doc[i:i+ws*2] for i, _ in enumerate(src_doc) if i <= len(src_doc) - ws*2]\n",
    "    \n",
    "    # 가끔 한문장이 너무길어서 잘리는 경우가 있음..\n",
    "    try:\n",
    "        div_scores = [get_divscore(src_doc=cand, embedder=embedder, divider=subtext_model) for cand in cands]\n",
    "        div_point = div_scores.index(max(div_scores)) + ws - 1\n",
    "\n",
    "        if div_point == gt:\n",
    "            acc_cnt += 1\n",
    "        else:\n",
    "            err_cnt += 1\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error occurred at {i}th article\")\n",
    "    \n",
    "#     sents = [sent for sent in src_doc.split('\\n') if sent]\n",
    "#     lh_sent, rh_sent = [], []\n",
    "#     for i, sent in enumerate(sents):\n",
    "#         if i <= div_point:\n",
    "#             lh_sent.append(sent)\n",
    "#         else:\n",
    "#             rh_sent.append(sent)\n",
    "            \n",
    "#     result_sents = lh_sent + [\"----------------[DIV]---------------\"] + rh_sent\n",
    "#     div_result.append((result_sents, div_scores, div_point, gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_cnt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91636c8cdc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{acc_cnt / (acc_cnt + err_cnt)*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_cnt' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{acc_cnt / (acc_cnt + err_cnt)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 기사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_list = mixed_doc_list[35][0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[충청일보 이정규기자] 폐원을 신청한 청주 은성유치원이 충북도교육감을 상대로 낸 행정소송을 취하하려했지만 도교육청이 이를 거부한 것으로 전해졌다.',\n",
       " \"6일 충북도교육청에 따르면 은성유치원은 지난 2017년 7월 도교육감을 상대로 '징계의결 요구 처분 취소' 청구소송을 낸 후 지난해 12월 27일 소취하 신청서를 재판부에 제출했다.\",\n",
       " '그러나 지난해 12월 4일 도교육청이 소취하에 동의하지 않는다는 의견을 내면서 재판이 재개됐다.',\n",
       " '도교육청은 2017년 사립유치원 종합감사를 통해 은성유치원 회계 비리를 적발하고, 원장 정직을 유치원측에 요구했다.',\n",
       " '은성유치원은 이에 반발해 도교육청에 대해 행정소송을 제기했다.',\n",
       " '도교육청이 소 취하를 거부한 이유는 소송을 진행해 사립유치원 감사 업무 기준이 되는 판례를 만들겠다는 것이다.',\n",
       " '교육청 관계자는 \"판례가 있게 되면 행정 추진 기준으로 삼을 수 있다\"며 \"법원의 최종 판단을 받기 위해 소취하에 부동의했다\"고 전했다.',\n",
       " \"은성유치원은 오는 28일까지 폐원하겠다며 청주시교육지원청에 '학교 폐쇄 인가신청서'를 제출했다.\",\n",
       " '이날은 재개된 소송의 다음 재판이 열리는 변론기일이다.',\n",
       " '재판 중 폐원이 완료되면 소송을 유지할 이익이 사라지기 때문에 법원이 선고 때 본안 판단없이 각하 결정할 공산이 크다.',\n",
       " \"배우 인교진과 최대철이 드라마 '동백꽃 필 무렵'에서 특급 카메오로 활약 했다.\",\n",
       " \"인교진과 최대철은 지난 30일 방송된 KBS2 수목극 '동백꽃 필 무렵'(극본 임상춘, 연출 차영훈)에서 강하늘의 두 형으로 등장했다.\",\n",
       " '아버지 제삿날을 맞아 덕순(고두심 분)의 식당에 찾아온 그림이었다.',\n",
       " '그 시간 용식(강하늘 분)은 동백(공효진 분)을 만나려다 정숙(이정은 분)의 \"동백이를 만나면 어머니는? 어중간하게 착하려면 그만 둬\"라는 말에 뭔가 결심한 듯 돌아왔고, 동백과 만남을 허락해달라고 엄마 덕순의 식당 문을 연 순간 형들과 마주쳤다.',\n",
       " '꽃을 든 용식을 본 둘째 형(인교진 분)은 \"누가 있는겨. 형들한테 상의를 해야지\"라고 궁금해했고, 첫째 형(최대철 분)은 \"결혼하기 전에 연애 많이 해봐\"라고 말했다.',\n",
       " '하지만 형들도 아이가 있는 미혼모 동백을 받아들이긴 어려웠고, \"엄마한테 못할 짓\"이라고 꾸짖었다.',\n",
       " '특히 둘째 형인 인교진은 \"너 차라리 방아깨비를 잡으러 다녀\"라고 말했고, 이에 용식은 눈을 부라려 보는 이로 하여금 웃음을 유발했다.',\n",
       " \"앞서 인교진과 최대철은 드라마 '백희가 돌아왔다'에서 만난 제작진과 의리로 출연한 것으로 알려졌다.\"]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:02<00:00,  7.36it/s]\n"
     ]
    }
   ],
   "source": [
    "score_list = []\n",
    "for i, sent in enumerate(tqdm(script_list)):\n",
    "    if i + (ws*2) <= len(script_list):\n",
    "        w_input = script_list[i:i+(ws*2)]\n",
    "        \n",
    "        # embedding\n",
    "        emb = embedder.get_embeddings(w_input).transpose(1, 0).cuda()\n",
    "        score = subtext_model(emb.unsqueeze(0))\n",
    "        score_list.append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-4.86625862121582,\n",
       " -5.065357685089111,\n",
       " -5.856250762939453,\n",
       " -4.983221530914307,\n",
       " -4.679341793060303,\n",
       " -4.1713433265686035,\n",
       " -4.891319751739502,\n",
       " 8.072851181030273,\n",
       " -3.0970635414123535,\n",
       " -3.884166955947876,\n",
       " -7.703949928283691,\n",
       " -5.633543491363525,\n",
       " -6.8576555252075195]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[충청일보 이정규기자] 폐원을 신청한 청주 은성유치원이 충북도교육감을 상대로 낸 행정소송을 취하하려했지만 도교육청이 이를 거부한 것으로 전해졌다.\n",
      "6일 충북도교육청에 따르면 은성유치원은 지난 2017년 7월 도교육감을 상대로 '징계의결 요구 처분 취소' 청구소송을 낸 후 지난해 12월 27일 소취하 신청서를 재판부에 제출했다.\n",
      "그러나 지난해 12월 4일 도교육청이 소취하에 동의하지 않는다는 의견을 내면서 재판이 재개됐다.\n",
      "-4.87 \n",
      " 도교육청은 2017년 사립유치원 종합감사를 통해 은성유치원 회계 비리를 적발하고, 원장 정직을 유치원측에 요구했다.\n",
      "-5.07 \n",
      " 은성유치원은 이에 반발해 도교육청에 대해 행정소송을 제기했다.\n",
      "-5.86 \n",
      " 도교육청이 소 취하를 거부한 이유는 소송을 진행해 사립유치원 감사 업무 기준이 되는 판례를 만들겠다는 것이다.\n",
      "-4.98 \n",
      " 교육청 관계자는 \"판례가 있게 되면 행정 추진 기준으로 삼을 수 있다\"며 \"법원의 최종 판단을 받기 위해 소취하에 부동의했다\"고 전했다.\n",
      "-4.68 \n",
      " 은성유치원은 오는 28일까지 폐원하겠다며 청주시교육지원청에 '학교 폐쇄 인가신청서'를 제출했다.\n",
      "-4.17 \n",
      " 이날은 재개된 소송의 다음 재판이 열리는 변론기일이다.\n",
      "-4.89 \n",
      " 재판 중 폐원이 완료되면 소송을 유지할 이익이 사라지기 때문에 법원이 선고 때 본안 판단없이 각하 결정할 공산이 크다.\n",
      "8.07 \n",
      " 배우 인교진과 최대철이 드라마 '동백꽃 필 무렵'에서 특급 카메오로 활약 했다.\n",
      "-3.10 \n",
      " 인교진과 최대철은 지난 30일 방송된 KBS2 수목극 '동백꽃 필 무렵'(극본 임상춘, 연출 차영훈)에서 강하늘의 두 형으로 등장했다.\n",
      "-3.88 \n",
      " 아버지 제삿날을 맞아 덕순(고두심 분)의 식당에 찾아온 그림이었다.\n",
      "-7.70 \n",
      " 그 시간 용식(강하늘 분)은 동백(공효진 분)을 만나려다 정숙(이정은 분)의 \"동백이를 만나면 어머니는? 어중간하게 착하려면 그만 둬\"라는 말에 뭔가 결심한 듯 돌아왔고, 동백과 만남을 허락해달라고 엄마 덕순의 식당 문을 연 순간 형들과 마주쳤다.\n",
      "-5.63 \n",
      " 꽃을 든 용식을 본 둘째 형(인교진 분)은 \"누가 있는겨. 형들한테 상의를 해야지\"라고 궁금해했고, 첫째 형(최대철 분)은 \"결혼하기 전에 연애 많이 해봐\"라고 말했다.\n",
      "-6.86 \n",
      " 하지만 형들도 아이가 있는 미혼모 동백을 받아들이긴 어려웠고, \"엄마한테 못할 짓\"이라고 꾸짖었다.\n",
      "특히 둘째 형인 인교진은 \"너 차라리 방아깨비를 잡으러 다녀\"라고 말했고, 이에 용식은 눈을 부라려 보는 이로 하여금 웃음을 유발했다.\n",
      "앞서 인교진과 최대철은 드라마 '백희가 돌아왔다'에서 만난 제작진과 의리로 출연한 것으로 알려졌다.\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(script_list):\n",
    "    if (i >= ws) & (i <= len(script_list) - ws):\n",
    "        j = (i-ws)\n",
    "        print(f\"{score_list[j]:.2f}\", '\\n', sent)\n",
    "    else:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=3\n",
    "tmp_src = mixed_doc_list[100][0].split('\\n')\n",
    "tmp_cands = [tmp_src[i:i+ws*2] for i, _ in enumerate(tmp_src) if i <= len(tmp_src) - ws*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [get_divscore(src_doc=cand, embedder=embedder, divider=subtext_model) for cand in tmp_cands]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 유튜브"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import doc_preprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_script_pth = '/home/sks/korea_univ/21_1/TA/team_project/youtube_summarizer/dataset/youtube_dataset/label/KBS뉴스_sNMcImF7Ubo_27m_38s.txt'\n",
    "with open(youtube_script_pth, 'rb') as rr:\n",
    "    youtube_df = json.load(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = youtube_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_fin = doc_preprocess(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_list = [sent for sent in script_fin.split('\\n') if len(sent.strip()) >= 20]#[:50]\n",
    "#script_list = [sent for sent in script_fin.split('\\n')][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [00:25<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "subtext_model.eval()\n",
    "\n",
    "score_list = []\n",
    "for i, sent in enumerate(tqdm(script_list)):\n",
    "    if i + (ws*2) <= len(script_list):\n",
    "        w_input = script_list[i:i+(ws*2)]\n",
    "        \n",
    "        # embedding\n",
    "        emb = embedder.get_embeddings(w_input).transpose(1, 0).cuda()\n",
    "        score = subtext_model(emb.unsqueeze(0))\n",
    "        score_list.append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.3943195343017578,\n",
       " -6.566971778869629,\n",
       " -5.9564361572265625,\n",
       " -4.123239994049072,\n",
       " -5.181784629821777,\n",
       " -5.251582145690918,\n",
       " -6.510199546813965,\n",
       " -6.372408390045166,\n",
       " 0.538477897644043,\n",
       " -5.2188310623168945,\n",
       " -5.503244400024414,\n",
       " -5.466092586517334,\n",
       " -4.190450668334961,\n",
       " 8.113215446472168,\n",
       " -4.470927715301514,\n",
       " -1.239018201828003,\n",
       " -4.1706671714782715,\n",
       " -1.8685868978500366,\n",
       " -1.1108489036560059,\n",
       " -3.2292702198028564,\n",
       " -4.812061309814453,\n",
       " -2.418874979019165,\n",
       " 3.236466407775879,\n",
       " -5.411825180053711,\n",
       " -6.229593753814697,\n",
       " -1.3415755033493042,\n",
       " -6.690732955932617,\n",
       " -5.865991592407227,\n",
       " -5.601990699768066,\n",
       " -6.884272575378418,\n",
       " -6.069212913513184,\n",
       " -5.230625152587891,\n",
       " -5.326739311218262,\n",
       " -6.234976768493652,\n",
       " 1.0425372123718262,\n",
       " -6.210102081298828,\n",
       " -4.568972110748291,\n",
       " -5.4841814041137695,\n",
       " -6.131746292114258,\n",
       " -6.544376373291016,\n",
       " -6.337329387664795,\n",
       " -6.241468906402588,\n",
       " -6.131739616394043,\n",
       " -5.225009441375732,\n",
       " -4.9916605949401855,\n",
       " 1.2107954025268555,\n",
       " -2.4454524517059326,\n",
       " 5.633777618408203,\n",
       " -6.491326332092285,\n",
       " -5.925522804260254,\n",
       " -6.351621150970459,\n",
       " -6.356986999511719,\n",
       " -5.148321151733398,\n",
       " -6.671548366546631,\n",
       " -6.572088718414307,\n",
       " -5.763474941253662,\n",
       " -7.524040222167969,\n",
       " -7.806679725646973,\n",
       " -6.650539398193359,\n",
       " -7.214781761169434,\n",
       " -6.558156967163086,\n",
       " -5.951620101928711,\n",
       " -5.24264669418335,\n",
       " 6.006073474884033,\n",
       " -6.546083450317383,\n",
       " -3.388125419616699,\n",
       " 0.8440978527069092,\n",
       " -5.493377208709717,\n",
       " -4.5690178871154785,\n",
       " -4.734951496124268,\n",
       " 7.480896949768066,\n",
       " -5.702489376068115,\n",
       " -5.619654178619385,\n",
       " -6.800013542175293,\n",
       " -5.453115463256836,\n",
       " -5.408656597137451,\n",
       " -6.316486358642578,\n",
       " -5.413757801055908,\n",
       " -6.267025947570801,\n",
       " -6.342641830444336,\n",
       " -4.906774520874023,\n",
       " -5.697302341461182,\n",
       " 7.8688483238220215,\n",
       " -5.165799617767334,\n",
       " -1.2234560251235962,\n",
       " -4.720857620239258,\n",
       " 7.367313385009766,\n",
       " -5.744943141937256,\n",
       " -6.605967044830322,\n",
       " -6.602347373962402,\n",
       " -6.235764980316162,\n",
       " -6.398499011993408,\n",
       " -5.366305828094482,\n",
       " -6.303777694702148,\n",
       " -6.076601505279541,\n",
       " -6.763410568237305,\n",
       " -7.551938533782959,\n",
       " -7.324487209320068,\n",
       " -4.3555755615234375,\n",
       " -3.446166515350342,\n",
       " -5.8126726150512695,\n",
       " -6.83096170425415,\n",
       " -5.645987510681152,\n",
       " -5.751457214355469,\n",
       " -6.955653667449951,\n",
       " -7.806413650512695,\n",
       " -6.367216110229492,\n",
       " -5.533553600311279,\n",
       " -5.755168914794922,\n",
       " -6.026148319244385,\n",
       " -5.242486953735352,\n",
       " -6.5260138511657715,\n",
       " -3.273813486099243,\n",
       " -5.6765031814575195,\n",
       " -5.725119590759277,\n",
       " -6.01507568359375,\n",
       " -5.388635635375977,\n",
       " -6.774722576141357,\n",
       " -6.285038471221924,\n",
       " -5.582743167877197,\n",
       " -7.010376930236816,\n",
       " -5.076054096221924,\n",
       " -5.962813854217529,\n",
       " -0.27060115337371826,\n",
       " 5.564975738525391,\n",
       " -5.705169677734375,\n",
       " -5.62940788269043,\n",
       " -5.905725479125977,\n",
       " -7.049498558044434,\n",
       " -6.317221641540527,\n",
       " -6.072094917297363,\n",
       " -5.53669548034668,\n",
       " -1.1851357221603394,\n",
       " -5.472158908843994,\n",
       " -5.187247276306152,\n",
       " -3.244593620300293,\n",
       " -1.0028895139694214,\n",
       " 12.423659324645996,\n",
       " -5.671507358551025,\n",
       " -2.439785957336426,\n",
       " -5.790931701660156,\n",
       " -5.065900802612305,\n",
       " -4.661970138549805,\n",
       " -4.9249114990234375,\n",
       " -5.415172100067139,\n",
       " -5.474227428436279,\n",
       " -5.942524433135986,\n",
       " -7.344997406005859,\n",
       " 3.1638426780700684,\n",
       " 4.752646446228027,\n",
       " 6.0994672775268555,\n",
       " 0.6759463548660278,\n",
       " -7.027840614318848,\n",
       " -6.664353370666504,\n",
       " -4.808104515075684,\n",
       " -5.373531818389893,\n",
       " -0.32333099842071533,\n",
       " 3.187204599380493,\n",
       " 6.273523330688477,\n",
       " 8.263269424438477,\n",
       " -0.993882417678833,\n",
       " -6.084199905395508,\n",
       " -5.023093223571777,\n",
       " -6.259713172912598,\n",
       " -4.423454284667969,\n",
       " -6.132493495941162,\n",
       " -5.278354644775391,\n",
       " -4.148416042327881,\n",
       " -1.4676637649536133,\n",
       " -3.421945095062256,\n",
       " -5.017385959625244,\n",
       " -7.6320695877075195,\n",
       " -5.670312404632568,\n",
       " -6.9752960205078125,\n",
       " -7.699676036834717,\n",
       " -6.697163105010986,\n",
       " -6.068660259246826,\n",
       " -5.238100528717041,\n",
       " -6.643221378326416]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여러분 안녕하십니까 코로나19 통합뉴스룸 5시 뉴스입니다\n",
      "미국이 한국을 비롯한 세계 각국의 코로나19 백신을 제공하는 방안과 관련해 자국 우선 사용 원칙을 분명히 했습니다\n",
      "바이든 대통령 역시 현재로서는 해외 공급이 어렵다면서도 앞으로 그렇게 되길 바란다고 말했습니다\n",
      "-0.39 \n",
      " 미 국무부가 코로나19 백신의 해외 공유와 관련해 국내 공급이 우선이라고 밝혔습니다\n",
      "-6.57 \n",
      " 레드 프라이스 미 국무부 대변인은 코로나19 백신 확보를 위한 한미 백신 수확 후 협정 체결 가능성에 대한 질문에 포괄적으로 답하겠다며 이같이 말했습니다\n",
      "-5.96 \n",
      " 그러면서 바이든 정부는 현재 최대한 짧은 시간 안에 가장 빠른 속도로 미국 내 접종자 수를 늘리는 데 주력하고 있다고 설명했습니다\n",
      "-4.12 \n",
      " 56만여 명이 숨지고 3천만 명 넘는 확진자가 나온 미국 상황을 진정시키는 게 세계적 확산 방지 협력보다 중요하다는 점을 재확인한 겁니다\n",
      "-5.18 \n",
      " 이 같은 정책 방향을 반영하듯 현지시간 21일 미국 내 코로나19 백신 접종은 2억 회를 넘어섰습니다\n",
      "-5.25 \n",
      " 바이든 대통령은 역사적인 백신 접종 노력의 새 장을 열었다고 자평하면서도 해외 공유 가능성에 대해선 회의적 시각을 드러냈습니다\n",
      "-6.51 \n",
      " 바이든 대통령은 다만 각국의 상황에 도움을 주기 위해 안전성을 전제로 사용하지 않는 백신 가운데 일부를 어떻게 할지 살펴보는 중이라고 덧붙였습니다\n",
      "-6.37 \n",
      " 세계 각국이 빗발치는 요청에도 불구하고 미국이 집단 면역 전에 백신을 해외에 대규모로 공급하는 상황은 사실상 기대하기 어려워 보입니다\n",
      "========(0.54)======== \n",
      " 코로나19 신규 확진자는 오늘도 700명대로 지난 1월 첫째 주 이후 가장 높은 수치를 기록했습니다\n",
      "-5.22 \n",
      " 백신 수급 비판에 대해 정부는 이미 충분한 백신을 공급받기로 했다며 추가 확보를 위해 신규 백신 개발 동향도 주시하고 있다고 밝혔습니다\n",
      "-5.50 \n",
      " 오늘 0시 기준 코로나19 신규 확진자는 735명 어제보다 4명 늘어난 것으로 지난 1월 첫째 주 이후 3개월여 만에 가장 많은 수입니다\n",
      "-5.47 \n",
      " 지역별로는 서울 229명 경기 217명으로 가장 많았습니다\n",
      "-4.19 \n",
      " 접종 후 이상 반응으로 의심돼 신고된 사례는 199건 늘어 모두 1만 2천732건입니다\n",
      "========(8.11)======== \n",
      " 방역당국은 지난달 아스트라제네카를 접종한 뒤 뇌출혈 증세가 나타난 20대 공무원에 대한 1차 기초조사 결과 유럽의약품청 등이 인정한 희귀 혈전증과는 다른 것으로 보인다고 밝혔습니다\n",
      "-4.47 \n",
      " 뇌에 있는 혈관 기 이상이 있어서 혈관 기형이라고도 부를 수 있을 것 같은데요\n",
      "-1.24 \n",
      " 저희들이 지금 관심 가지고 바라보고 있는 혈소판 감소 등을 동반한 혈전증하고는 현재까지로는 좀 거리가 있는 이런 케이스인 걸로 아스트라제네카 백신을 맞은 뒤 사지 마비 증상을 겪은 40대 간호조무사에 대해서는 피해 보상 심사 결과가 나오기에 앞서 기존 복지제도를 통해 의료비를 지원한다는 방침입니다\n",
      "-4.17 \n",
      " 비슷한 중증 이상 반응 환자들에게도 지자체별로 1대1 전담자를 지정해 지원 방안을 찾기로 했습니다\n",
      "-1.87 \n",
      " 혈전 우려가 제기된 얀센 백신에 대해 유럽 국가들이 접종을 진행하기로 함에 따라 우리나라도 예정된 물량을 도입하기로 결정했다고 밝혔습니다\n",
      "-1.11 \n",
      " 유럽의약품청이 안전성 평가 결과 얀셈 백신의 부작용 위험에 비해 예방 효과가 더 크다고 발표한 데 따른 겁니다\n",
      "-3.23 \n",
      " 정부는 또 러시아 삼백신인 스프트니크 부위 도입 논의와 관련해 현재 외국의 검증 및 허가 동향을 파악하고 있다고 전했습니다\n",
      "-4.81 \n",
      " 당국은 최근 비판이 제기된 백신 수급과 관련해 소모적인 논쟁이 진행되고 있다면서 공급받기로 한 백신은 우리나라 인구 수가 넘는 7천9백만 명뿐이며 추가 물량을 확보하기 위한 노력도 병행하고 있다고 밝혔습니다\n",
      "-2.42 \n",
      " 이어 백신 접종 인원을 하루 30만 명 이상으로 늘려 이달 안으로 300만 명에 대한 접종을 마친다는 계획은 차질없이 달성할 수 있을 것으로 예상된다고 밝혔습니다\n",
      "========(3.24)======== \n",
      " 경기도는 222명의 신규 확진자가 발생했습니다\n",
      "-5.41 \n",
      " 안산의 한 대학교에서 학생 10여 명이 확진됐고 성남 분당의 노래방 관련 집단 감염은 인근 초등학교 등으로 확산하고 있습니다\n",
      "-6.23 \n",
      " 코로나19 신규 확진자는 어제보다 10여 명 줄어든 222명으로 이틀 연속 200명대를 보였습니다\n",
      "-1.34 \n",
      " 안산의 대학교에서 12명이 추가로 감염됐습니다\n",
      "-6.69 \n",
      " 지난 20일 대학교 기숙사에 거주하는 학생 1명이 확진된 뒤 다른 학생과 지인이 추가로 확진됐는데 이틀 새 확진자가 15명으로 늘어난 겁니다\n",
      "-5.87 \n",
      " 이 대학 기숙사엔 학생 400여 명이 거주하고 있으며 전교생은 3천여 명으로 파악됐습니다\n",
      "-5.60 \n",
      " 대학 측은 모레까지 모든 강의를 비대면으로 전환하고 이후 30일까지 휴강하기로 했습니다\n",
      "-6.88 \n",
      " 성남 분당구 노래방 관련 집단 감염은 종사자와 방문자 지인 가족 등으로 확산하고 있습니다\n",
      "-6.07 \n",
      " 특히 지난 9일 확진된 초등학교 교사가 해당 노래방을 방문한 것으로 확인되면서 추적 조사를 통해 학생 등의 확진도 잇따르고 있습니다\n",
      "-5.23 \n",
      " 노래방 관련 확진자는 4명이 더 나와 지난 6일 이후 모두 78명이 양성 판정을 받았습니다\n",
      "-5.33 \n",
      " 의정부 교회 관련 확진자도 1명이 더 늘어 지난 15일 이후 누적 확진자는 29명이 됐습니다\n",
      "-6.23 \n",
      " 신규 확진자 222명 가운데 감염 경로가 명확하지 않아 조사 중인 경우는 52명으로 신규 확진자의 23%입니다\n",
      "========(1.04)======== \n",
      " 코로나19로 인한 고용 충격이 남성보다는 여성 특히 기혼 여성에 많이 집중됐다는 연구 결과가 나왔습니다\n",
      "-6.21 \n",
      " 대면업종에 여성 종사자가 많은데다 자녀 돌봄에 대한 부담까지 더해졌기 때문으로 분석됩니다\n",
      "-4.57 \n",
      " 코로나19 고용 충격이 본격화된 지난해 3월 kdi가 분류한 25세에서 54세 여성 취업자 수는 1년 전보다 54만여 명 감소했습니다\n",
      "-5.48 \n",
      " 같은 기간 남성이 32만여 명 감소한 것에 비해 65% 많은 수준입니다\n",
      "-6.13 \n",
      " 이런 현상을 놓고 kdi는 먼저 업종 특성에서 원인을 찾았습니다\n",
      "-6.54 \n",
      " 코로나19로 인한 영업 제한 같은 충격이 대면 서비스업종에 집중됐는데 해당 분야에서 일하는 여성의 숫자가 많았기 때문입니다\n",
      "-6.34 \n",
      " 고용 충격이 큰 상위 3개 업종 교육과 숙박 음식 사회복지 분야의 경우 성별 취업자 비중은 여성이 38%로 13%인 남성보다 크게 높았습니다\n",
      "-6.24 \n",
      " 여기에 코로나19로 인한 자녀 양육여건 악화도 원인으로 꼽혔습니다\n",
      "-6.13 \n",
      " 코로나19로 보육시설 운영이 중단되고 학교 수업도 차질을 빚으면서 가정 내 돌봄 부담이 여성 특히 기혼 여성에게 집중됐다는 분석입니다\n",
      "-5.23 \n",
      " 실제 기혼 여성의 경제활동 중단 확률은 코로나 이전보다 2%포인트 높아져 0.5%포인트 증가에 그친 기혼 남성보다 높았습니다\n",
      "-4.99 \n",
      " 연령별 분석 결과 39세에서 44세 초등학생 자녀가 있을 것으로 추측되는 집단에서 경제활동을 중단할 확률의 성별 격차가 가장 크게 나타났습니다\n",
      "========(1.21)======== \n",
      " kdi는 여성의 이른 경력단절은 영구적인 인적 자본의 손실로 이어질 수 있다며 자녀 돌봄 등에 대한 사회적 지원이 필요하다고 강조했습니다\n",
      "-2.45 \n",
      " 또 실직자들이 쉽게 일터로 돌아갈 수 있는 방안을 마련하는 것도 중요한 일이라고 덧붙였습니다\n",
      "========(5.63)======== \n",
      " 관심이 모아졌던 수도권 광역급행철도노선 gtx d의 윤곽이 드러났습니다\n",
      "-6.49 \n",
      " gtx는 김포 장기에서 부천 종합운동장까지만 연결될 예정입니다\n",
      "-5.93 \n",
      " 앞으로 10년간의 국가철도망 구축 계획안이 나왔습니다\n",
      "-6.35 \n",
      " 국토부 연구용역을 맡은 한국교통연구원이 노선을 공개한 겁니다\n",
      "-6.36 \n",
      " 그중 가장 관심을 끌었던 수도권 서부권 광역급행철도인 gtx 신설 노사는 김포 장기에서 부천 종합운동장까지 있습니다\n",
      "-5.15 \n",
      " 이에 따라 김포에서 부천까지 이동시간이 69분에서 15분으로 줄어들게 될 것으로 보입니다\n",
      "-6.67 \n",
      " 다만 수도권 일부 지자체들이 요구해온 노선보다는 비교적 축소된 규모입니다\n",
      "-6.57 \n",
      " 교통연구원 측은 사업 타당성이나 수도권 지방간 투자 균형에 더해 기존 노선 영향까지 고려했다고 밝혔습니다\n",
      "-5.76 \n",
      " gtx 노선 외에 전국적인 철도 청사진도 함께 나왔습니다\n",
      "-7.52 \n",
      " 수색에서 금천구청 또 경부고속선 광명에서 평택 구간 등 열차 운행이 집중된 구간에 선로 용량이 확충됩니다\n",
      "-7.81 \n",
      " 또 인천공항 철도도 급행으로 전환해 gtx급으로 속도를 올릴 예정입니다\n",
      "-6.65 \n",
      " 이와 함께 지방 대도시 권역에도 광역 철도를 대폭 늘립니다\n",
      "-7.21 \n",
      " 부산에서 양산을 거쳐 울산으로 가는 광역 노선과 대전에서 세종을 지나 충북으로 가는 광역철도 등이 그 예시입니다\n",
      "-6.56 \n",
      " 여기다 고속철도 이용이 불편했던 서해안 등에도 새로 고속철도를 개통시키고 오래된 노선에는 고속화 사업도 진행될 예정입니다\n",
      "-5.95 \n",
      " 또 동해선 등 진행 중인 남북철도 연결사업과 대륙철도 연계에도 대비한다는 게 한국교통연구원의 설명입니다\n",
      "-5.24 \n",
      " 연구원 측은 총 투자 규모가 114조 7천억 원 향후 10년 안에만 총 90조 원이 투입된다고 밝혔습니다\n",
      "========(6.01)======== \n",
      " 지난해 6월 기준으로 sh공사가 매입해 보유 중인 임대주택 가운데 24%가 빈집이었고 이 중 72%가량인 3천3백여 호는 6개월 이상 비어 있었던 것으로 감사원 감사 결과 드러났습니다\n",
      "-6.55 \n",
      " 특히 2017년 1월부터 2019년 12월 사이에 사들인 임대주택 중 1166호는 한 번도 입주자가 없었던 것으로 확인됐습니다\n",
      "-3.39 \n",
      " 감사원은 sh공사가 연간 공급 목표 5천 호 달성을 위해 수요 등을 고려하지 않은 채 임대주택을 사들였고 이후 빈집에 대한 관리 대책도 부적절했다고 판단해 대책을 마련하라고 통보했습니다\n",
      "========(0.84)======== \n",
      " 청와대가 중앙부처 지방자치단체 공무원은 물론 전국 공공기관 임직원들의 각종 권한 남용 행위를 집중 감찰하기로 했습니다\n",
      "-5.49 \n",
      " 청와대는 오늘 반부패비서관실 주관으로 공직기강협의체 회의를 긴급 개최해 이같이 결정했다고 밝혔습니다\n",
      "-4.57 \n",
      " 청와대는 감찰 배경에 대해 최근 일부 공직자 등의 부정 의혹이 발생했다며 공직 비리에 대한 전반적 점검이 중요한 상황이라고 설명했습니다\n",
      "-4.73 \n",
      " 공직기강협의체는 지난 2019년 1월에 만들어졌으며 이번이 6번째 회의입니다\n",
      "========(7.48)======== \n",
      " 공직자가 직무 수행 중 얻게 된 정보를 이용해 사적 이익을 추구하지 못하도록 하는 이해충돌방지법이 국회 정무위원회를 통과했습니다\n",
      "-5.70 \n",
      " 이른바 국회의원 이해충돌방지법으로 불리는 국회법 개정안도 상임위 문턱을 넘었습니다\n",
      "-5.62 \n",
      " 국회 정무위원회는 오늘 전체회의를 열어 공직자의 이해충돌방지법 제정안을 통과시켰습니다\n",
      "-6.80 \n",
      " 법안은 공직자가 직무수행 중 알게 된 비밀이나 미공개 정보를 이용해 사적 이익을 추구하지 못하도록 하는 내용을 골자로 하고 있습니다\n",
      "-5.45 \n",
      " 공무원과 공공기관 임직원을 포함해 법의 적용 대상은 모두 190만 명에 달하고 이들의 직계 좀비 속을 포함하면 5600만 명이 법의 영향을 받을 것으로 보입니다\n",
      "-5.41 \n",
      " 이해충돌방지법은 지난 8년 동안 발의가 계속돼 오다가 최근 lh 직원들의 땅 투기 의혹을 계기로 논의가 급속히 진전됐습니다\n",
      "-6.32 \n",
      " 공직자 중 차관급 이상 공무원과 국회의원 지방의원 정무직 공무원 공공기관 임원 등은 고위공직자로 분류돼 가족이 채용 등에 있어 더 강한 규제를 받습니다\n",
      "-5.41 \n",
      " 제3자가 미공개 정보를 얻어 부당한 이득을 취할 경우에도 처벌 대상이 됩니다\n",
      "-6.27 \n",
      " 이 법에 빠진 국회의원의 사적 이해관계 사전 신고와 이 가운데 본인에 관한 사항을 공개하기 위한 국회법 개정안도 국회 운영위를 통과했습니다\n",
      "-6.34 \n",
      " 이해관계가 겹치는 상임위 배정과 안건 심사를 제한하는 내용도 포함됐습니다\n",
      "-4.91 \n",
      " 국회의원은 앞으로 본인과 배우자 등이 임원인 법인 명단과 부동산 보유 현황 등을 등록해야 하고 국회 윤리심사자문위원회는 이를 토대로 의원의 이해충돌 여부에 대한 의견을 내놔야 합니다\n",
      "-5.70 \n",
      " 이해충돌방지법 제정안과 국회법 개정안은 국회 법사위를 거쳐 오는 29일 본회의에서 통과될 것으로 보입니다\n",
      "========(7.87)======== \n",
      " 문재인 대통령이 오늘 밤 조 바이든 미국 대통령의 초청으로 세계 기후 정상회의에 참석합니다\n",
      "-5.17 \n",
      " 화상으로 열리는 이번 회의는 온실가스 배출량 감축을 담은 파리협정 목표와 2050년 탄소 중립 달성을 위한 각국에 상향된 기후 대응 의지를 결집하기 위해 마련됐습니다\n",
      "-1.22 \n",
      " 특히 미중 갈등이 날로 첨예해지는 가운데 문 대통령이 화상으로 바이든 미국 대통령과 시진핑 중국 국가주석을 동시에 대면하게 됩니다\n",
      "-4.72 \n",
      " 문 대통령과 바이든 대통령이 얼굴을 마주하는 것은 이번이 처음입니다\n",
      "========(7.37)======== \n",
      " 삼성물산과 제일모직 합병 등을 둘러싸고 경영권 불법 승계 의혹으로 기소된 이재용 삼성전자 부회장의 첫 재판이 오늘 열렸습니다\n",
      "-5.74 \n",
      " 최근 충수염 수술을 받은 이 부회장도 법정에 출석했습니다\n",
      "-6.61 \n",
      " 이재용 삼성전자 부회장은 이른바 경영권 불법 승계 의혹으로 지난해 9월 재판에 넘겨졌습니다\n",
      "-6.60 \n",
      " 기소 7개월여 만인 오늘 서울중앙지법에서 첫 재판이 열렸습니다\n",
      "-6.24 \n",
      " 최근 충수염 수술을 받은 이 부회장은 다소 수척해진 모습으로 법정에 나왔습니다\n",
      "-6.40 \n",
      " 이 부회장 측 변호인은 재판에 앞서 재판부가 기일 변경을 해준 덕에 이 부회장이 위급한 상황을 넘기고 건강을 회복 중에 있다고 말했습니다\n",
      "-5.37 \n",
      " 오전 재판에서 검찰은 삼성그룹의 지배권 승계를 위해 이 부회장 등 삼성 관계자들이 불법을 저질렀다고 밝혔습니다\n",
      "-6.30 \n",
      " 지난 2015년 삼성물산과 제일모직 합병 과정에서 이 부회장의 승계에 유리한 조건을 만들기 위해 삼성 측이 거짓 정보를 유포하는 등 주식 시세를 조종해 삼성물산 주주들에게 막대한 손해를 끼쳤다는 겁니다\n",
      "-6.08 \n",
      " 검찰은 특히 이 부회장이 불법 합병 과정을 보고받고 승인한 것으로 의심하고 있습니다\n",
      "-6.76 \n",
      " 이에 대해 이 부회장 측은 두 기업의 합병이 경영상 필요에 의해 합법적으로 이뤄졌다며 무죄를 주장했습니다\n",
      "-7.55 \n",
      " 또 이 부회장의 지배력 강화라는 목적이 부당하다고는 볼 수 없고 합병 과정도 사실 그대로 공표했다고 강조했습니다\n",
      "-7.32 \n",
      " 이 부회장 측은 검사가 이 부회장 등을 마치 범죄단체로 보는 게 아닌가 생각될 정도라며 불만을 나타내기도 했습니다\n",
      "-4.36 \n",
      " 이 부회장은 지난 1월 국정농단 사건 파기환송심에서 징역 2년 6개월을 확정받고 수감된 상태입니다\n",
      "-3.45 \n",
      " 지난달 대전의 한 어린이집 원장이 생후 21개월 된 여아를 재운다며 몸으로 아이를 눌러 숨지게 한 사건이 있었는데요\n",
      "-5.81 \n",
      " 당시 cctv가 공개됐는데 학대 정황이 고스란히 드러났습니다\n",
      "-6.83 \n",
      " 부검 결과 질식사 소견이 나온 것으로 알려진 가운데 경찰은 구속영장을 다시 신청할 방침입니다\n",
      "-5.65 \n",
      " 어린이집 원장이 낮잠을 자는 아이들 사이에 21개월 된 여아를 내려놓고 이불로 싸맵니다\n",
      "-5.75 \n",
      " 그리고는 옆에 눕더니 엎드린 아이 위로 자신의 팔과 다리를 올린 몸을 기울여 누르기 시작합니다\n",
      "-6.96 \n",
      " 이런 자세는 10분여 동안 계속됐습니다\n",
      "-7.81 \n",
      " 몸이 눌린 아이는 조금 뒤 움직임을 멈춥니다\n",
      "-6.37 \n",
      " 1시간쯤 뒤 아이가 숨을 쉬지 않는 걸 확인한 원장이 심폐소생술을 하지만 아이는 끝내 숨졌습니다\n",
      "-5.53 \n",
      " 앞서 경찰은 이 cctv를 근거로 원장에 대해 아동학대치사 혐의로 구속영장을 신청했지만 검찰에서 보완 수사가 필요하다며 반려됐습니다\n",
      "-5.76 \n",
      " 경찰은 국과수의 부검 결과 아이가 질식사했다는 소견을 통보받은 것으로 알려졌습니다\n",
      "-6.03 \n",
      " 경찰은 원장에 대해 구속영장을 재신청할 예정입니다\n",
      "-5.24 \n",
      " 유가족들은 원장의 행동에 미필적 고의가 있었다며 살인 혐의를 적용해야 한다고 주장합니다\n",
      "-6.53 \n",
      " 아기의 얼굴을 바닥으로 눕히고 거기다 지금 이불을 덮고 그리고 자기의 체중을 다시 잃었다는 것은 경험 직상 이 위험을 인식할 수 있기 때문에 미필적 고의가 있다고 유가족 측은 원장에 대해 아동학대 살해 혐의를 적용해달라고 요구했습니다\n",
      "-3.27 \n",
      " 지난 2월 경북 구미의 한 빈집에서 3살 여자아이가 숨진 채 발견된 사건에 대한 첫 재판이 오늘 열렸습니다\n",
      "-5.68 \n",
      " 숨진 아이의 친모 성모 씨는 출산 사실을 여전히 완강히 부인했지만 시신을 유기하려 했다는 혐의는 인정했습니다\n",
      "-5.73 \n",
      " 경북 구미에서 방치된 채 숨진 3살 여자아이의 친모 성모 씨가 고개를 숙인 채 법원으로 들어섭니다\n",
      "-6.02 \n",
      " 석 씨는 미성년자 약취와 사체 은닉 미수 혐의를 받고 있습니다\n",
      "-5.39 \n",
      " 검찰은 첫 재판에서 석 씨가 구미의 한 산부인과에서 친딸 22살 김 모 씨가 낳은 아이와 자신이 출산한 아이를 바꿔치기해 미성년자를 약취했다고 밝혔습니다\n",
      "-6.77 \n",
      " 다만 산부인과에서 어떻게 바꿔치기했는지 이후 어떻게 데리고 나왔는지를 명확히 입증하지 못했습니다\n",
      "-6.29 \n",
      " 이에 대해 석 씨의 변호인은 바꿔치기하려면 아이가 2명 있어야 하는데 석 씨는 출산 사실이 없어 혐의의 전제가 성립하지 않는다고 주장했습니다\n",
      "-5.58 \n",
      " 다만 숨진 아이의 시신을 유기하려 했다는 혐의는 인정했습니다\n",
      "-7.01 \n",
      " 거기에는 공수사실 제1항하고 관련되거나 그걸 추단할 수 있을 만한 사실이 공소사실이 없습니다\n",
      "-5.08 \n",
      " 법정 밖에선 석 씨에게 강력한 처벌을 해달라는 시위가 벌어졌습니다\n",
      "-5.96 \n",
      " 생명을 잔인하게 방치를 해서 죽인 거기 때문에 그만큼자기가 저지른 그 죄라면 당연히 그만큼의 죗값은 받아야 한다고 다음 재판은 다음 달 11일 열립니다\n",
      "-0.27 \n",
      " 군이 영화 사건에 대한 본격적인 법원의 시간이 시작된 가운데 숨진 아이와 아이 바꿔치기 의혹 등을 둘러싼 진실이 규명될 수 있을지 주목됩니다\n",
      "========(5.56)======== \n",
      " 어제 청주 대청호에서 화재 진압을 위해 물을 담던 헬기가 추락해 2명의 사상자가 나왔는데요\n",
      "-5.71 \n",
      " 전문가들은 헬기가 하강해 물을 퍼 담는 이런 담수 작업이 사고 우려가 크다고 지적합니다\n",
      "-5.63 \n",
      " 조종사 1명이 숨지고 1명이 다친 산불 진화용 헬기가 추락한 대청호 일대입니다\n",
      "-5.91 \n",
      " 사고 헬기가 수심 20m까지 가라앉은 가운데 기름 유출을 막는 긴급 방제가 한창입니다\n",
      "-7.05 \n",
      " 국토부 사고조사위는 헬기를 인양하는 대로 동체의 비행기록 장치를 확인하는 등 사고 조사에 착수할 예정입니다\n",
      "-6.32 \n",
      " 사고 헬기는 불을 끌어가다 물을 퍼 담는 과정에서 추락한 것으로 추정됩니다\n",
      "-6.07 \n",
      " 블랙박스 수고를 한 상태에서 있는 비행 자료 장치를 하면 일반적인 데이터는 많이 추출할 수 있을 거라고 생각됩니다\n",
      "-5.54 \n",
      " 이런 담수 과정은 헬기 조종사에게 사고 우려가 큰 위험한 작업이라고 전문가들은 지적합니다\n",
      "-1.19 \n",
      " 저공 비행 상태에서 조종사 스스로 헬기와 수면 사이의 높이를 판단하면서 물을 채워야 해섭니다\n",
      "-5.47 \n",
      " 2018년 3명의 사상자를 낸 한강헬기 추락도 사고 조사 결과 급하게 비행 고도를 낮췄던 것이 주원인으로 지목됐습니다\n",
      "-5.19 \n",
      " 물에 파동을 잘 인지를 못하면서 항공기가 내려가는 거나 올라갈 수 있습니다\n",
      "-3.24 \n",
      " 수면에 접촉하면 헬기는 전복이 되게 돼 있습니다\n",
      "-1.00 \n",
      " 국토부는 사고 헬기를 인양하는 대로 서울 김포공항 시험 분석실로 옮겨 세부 조사할 예정입니다\n",
      "========(12.42)======== \n",
      " 일본의 원전 오염수 방류 결정과 관련해 부산 환경운동연합이 도쿄 전력을 상대로 방류 금지 소송을 제기했습니다\n",
      "-5.67 \n",
      " 일본 정부의 오염수 방류를 막아달라는 첫 법적 조치입니다\n",
      "-2.44 \n",
      " 부산 환경운동연합이 원전 오염수 방류금지 청구 소송을 오늘 부산지법에 제기했습니다\n",
      "-5.79 \n",
      " 소송 대상은 일본 후쿠시마 제1원전 운영사 도쿄전력 홀딩스 주식회사입니다\n",
      "-5.07 \n",
      " 일본 정부가 오염수 방류를 결정한 뒤 국내에서 제기된 첫 소송입니다\n",
      "-4.66 \n",
      " 부산환경운동연합은 이웃 거주자 생활에 고통을 주지 않도록 해야 한다는 현행법 규정을 소송의 근거로 제시했습니다\n",
      "-4.92 \n",
      " 1급 발암물질인 세슘과 스트론 흉 등은 아무리 희석해도 인체에 유해한 만큼 일본의 오염수 방류는 우리 국민의 건강에 악영향을 미칠 수 있다는 겁니다\n",
      "-5.42 \n",
      " 방류량을 희석시켜서 서서히 20년 30년에 걸쳐서 방류 하겠다고 하더라도 해양 생물들이 먹게 되었을 때는 먹이사슬을 통해서 더욱더 농축 되어서 우리에게 들어올 것이라고 소송 대리인 측은 일본의 해양 방류 시점인 2023년 전까지 1심 판결 결과가 나올 것으로 예상했습니다\n",
      "-5.47 \n",
      " 우리의 주권에서 판단을 받는 게 굉장히 의미가 있다고 봅니다\n",
      "-5.94 \n",
      " 신속하게 제기해서 해양 방류를 금지하는 판결을 빨리 받아들여야 합니다\n",
      "-7.34 \n",
      " 만약 소송 과정에서 방류가 진행될 경우 금전적 책임도 묻겠다는 전략입니다\n",
      "========(3.16)======== \n",
      " 오염수 방류 결정에 대한 사회 각계의 반발이 거센 가운데 이번 소송이 방류 금지에 대한 법적 근거를 마련할 수 있을지 관심이 쏠리고 있습니다\n",
      "========(4.75)======== \n",
      " 오늘은 지구의 날이자 자전거의 날인데요\n",
      "========(6.10)======== \n",
      " 이를 기념해 환경과 건강을 모두 챙기자는 취지의 자전거 출퇴근 챌린지 운동이 시작됐습니다\n",
      "========(0.68)======== \n",
      " 이른 아침 헬멧과 자전거를 챙겨 집을 나서는 30대 직장인 유병용 씨 올해로 7년째 자전거를 타고 출퇴근하고 있습니다\n",
      "-7.03 \n",
      " 집에서 12km 떨어진 직장까지 걸리는 시간은 약 50분 따로 시간을 내지 않아도 아침저녁 자연스럽게 운동이 되고 출퇴근 시간 혼잡한 도로를 벗어날 수 있어 좋습니다\n",
      "-6.66 \n",
      " 기초적인 운동은 어느 정도 되는 부분이 있고요 그리고 뭐 자연경관 보면서 아침마다 그리고퇴근하면서 스트레스를 푸는 그런 유 씨처럼 승용차 대신 자전거 이용자를 늘려 환경과 건강 모두를 지키자는 취지에서 환경단체들이 자전거 출퇴근 챌린지를 시작했습니다\n",
      "-4.81 \n",
      " 오늘 자전거의 날이자 제51회 지구의 날을 기념해 앞으로 51일 동안 진행됩니다\n",
      "-5.37 \n",
      " 환경단체가 만든 에코바이크 앱을 이용하면 자전거로 출퇴근할 때마다 자신이 얼마나 대기오염을 줄이고 탄소 중립을 실천하는지 곧바로 알 수 있습니다\n",
      "-0.32 \n",
      " 자전거를 타시면 키로스에 따라서 내가 온실가스를 얼마만큼 감추고 했는지 그리고 에너지를 얼마나 절감했는지 그리고 나무를 얼마나 많은 심은 그런 효과를 냈는지 그런 자동차 대신 자전거를 이용할 경우 주행거리 1km당 온실가스 감축 효과는 0.1kg 정도입니다\n",
      "========(3.19)======== \n",
      " 각종 환경오염과 온실가스로 인한 지구온난화로 몸살을 앓고 있는 지구 자전거 출퇴근 같은 일상생활 작은 노력이 지구를 살리는 실천 운동으로 확산되고 있습니다\n",
      "========(6.27)======== \n",
      " 이어서 오늘의 주식시황을 kb증권에서 전해드립니다\n",
      "========(8.26)======== \n",
      " 장중 3190선까지 오르기도 했던 코스피 지수가 외국인의 매도 전환에 상승폭을 축소하며 강보합권에서 장을 마쳤습니다\n",
      "-0.99 \n",
      " 코스닥은 외국인과 기관의 매수에 힘입어 소폭 올랐습니다\n",
      "-6.08 \n",
      " 오늘 코스피는 5.86포인트 상승한 3177.52에 코스닥은 3.49포인트 오른 1025.71에 마감됐습니다\n",
      "-5.02 \n",
      " 전임 미국 증시는 경제 회복에 가장 민감한 종목들에 대한 강력한 저가 매수세가 유입되면서 사흘 만에 반등했습니다\n",
      "-6.26 \n",
      " 이런 가운데 코스피는 개인의 매수에 힘입어 강보한 마감했습니다\n",
      "-4.42 \n",
      " lg디스플레이가 oled 패널 수익성 개선에 따른 흑자 전환 전망에 6% 넘게 올랐고 롯데케미칼은 1분기 실적 개선 기대감이 높아지며 강세를 보였습니다\n",
      "-6.13 \n",
      " 또 문재인 대통령이 러시아산 코로나19 백신 도입 가능성 점검을 지시하면서 관련주인 eid와 이트론이 가격 제한폭까지 급등했습니다\n",
      "-5.28 \n",
      " 반면 삼성바이오로직스는 외국인의 차익 실현에 연이틀 저조한 흐름을 이어갔습니다\n",
      "-4.15 \n",
      " 오늘 원 달러머니는 1원 30전 내린 1117원 30전에 거래를 마쳤습니다\n",
      "-1.47 \n",
      " 오늘은 구름이 해를 가리면서 어제보다 기온이 덜 오르긴 했지만 그래도 때 이른 더위는 계속됐는데요\n",
      "-3.42 \n",
      " 오늘 한낮에 서울이 27.5도로 6월 하순의 더위를 보였습니다\n",
      "-5.02 \n",
      " 내일은 전국이 흐리고 곳곳에 비가 내리면서 낮 기온이 평년 수준 가까이 내려가겠습니다\n",
      "-7.63 \n",
      " 내일과 주말 동안 서울 낮 기온 23도로 예상됩니다\n",
      "-5.67 \n",
      " 내일 새벽부터 아침 사이 서쪽 지역 곳곳에서는 비가 조금 내리겠는데요\n",
      "-6.98 \n",
      " 수도권과 충청 호남과 제주에서는 5mm 미만의 비가 살짝 지나겠습니다\n",
      "-7.70 \n",
      " 이렇게 비의 양이 워낙 적어서 대기의 건조함은 계속되겠는데요\n",
      "-6.70 \n",
      " 오늘 중부 내륙으로 건조주의보가 확대됐고요 현재 서울을 비롯한 전국 곳곳에 건조주의보가 발효 중입니다\n",
      "-6.07 \n",
      " 내일은 하늘이 흐리고 서쪽 지역은 아침에 비가 조금 내리겠고요 낮 동안에 곳곳에서 빗방울이 떨어지는 곳이 있겠습니다\n",
      "-5.24 \n",
      " 아침 기온은 서울이 16도로 오늘과 비슷하게 출발하겠습니다\n",
      "-6.64 \n",
      " 한낮 기온은 서울이 23도 강릉 16도 대구가 20도 부산 19도로 오늘보다 4~7도 정도 낮겠습니다\n",
      "물결은 서해상과 제주 해상 남해상에서 최고 4m까지 높게 일겠습니다\n",
      "코로나19 통합 뉴스룸은 7시 뉴스에서 이어집니다\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(script_list):\n",
    "    if (i >= ws) & (i <= len(script_list) - ws):\n",
    "        j = (i-ws)\n",
    "        if score_list[j] > 0:\n",
    "            print(f\"========({score_list[j]:.2f})========\", '\\n', sent)\n",
    "        else:\n",
    "            print(f\"{score_list[j]:.2f}\", '\\n', sent)\n",
    "    else:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta_youtube",
   "language": "python",
   "name": "ta_youtube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
